{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to take in preprocessed data from silnlp, format it into json format for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Prepare data for a casual LLM\n",
    "#\n",
    "# src_file_path (string): location of src file\n",
    "# trg_file_path (string): location of trg file\n",
    "# output_file_path (string): location to save prepared json file\n",
    "# src (string): language/script tag (e.g., eng_Latn) for src data\n",
    "# trg (string): language/script tag (e.g., eng_Latn) for trg data\n",
    "#\n",
    "def prepare_data_for_causal_llm(src_file_path, trg_file_path, output_file_path,src,trg):\n",
    "    with open(src_file_path, 'r', encoding='utf-8') as src_file, open(trg_file_path, 'r', encoding='utf-8') as trg_file:\n",
    "        src_sentences = src_file.readlines()\n",
    "        trg_sentences = trg_file.readlines()\n",
    "\n",
    "        assert len(src_sentences) == len(trg_sentences), \"Files must have the same number of lines\"\n",
    "\n",
    "        with open(output_file_path, 'w') as output_file:\n",
    "            for src_sentence, trg_sentence in zip(src_sentences, trg_sentences):\n",
    "                # Combine src and trg for model input\n",
    "                model_input = f\"translate \"+src+\" to \"+trg+\": \"+src_sentence.strip()# + \" \" + trg_sentence.strip()\n",
    "                completion = f\"{trg_sentence.strip()}\\r\\n\"\n",
    "                data = {\n",
    "                    \"model_inputs\": model_input,\n",
    "                    \"completion\": completion\n",
    "                }\n",
    "                json.dump(data, output_file)\n",
    "                output_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark languages \n",
    "\n",
    "# List of all languages\n",
    "# each language: [language name (folder name), source language, target language]\n",
    "language_data = [['balti','urd_Arab','bft_Arab'],\n",
    "                 ['bana','fra_Latn','bcw_Latn'],\n",
    "                 ['bantawa','npi_Deva','bap_Deva'],\n",
    "                 ['borong','tpi_Latn','ksr_Latn'],\n",
    "                 ['gutob_gadaba','ory_Odia','gbj_Odia'],\n",
    "                 ['hejazi','arb_Arab','acw_Arab'],\n",
    "                 ['kisar','ind_Latn','kje_Latn'],\n",
    "                 ['konda_dora','tel_Telu','kfc_Telu'],\n",
    "                 ['kuvi','eng_Latn','kxv_Telu'],\n",
    "                 ['kwaraae','eng_Latn','kwf_Latn'],\n",
    "                 ['limbum','eng_Latn','lmp_Latn'],\n",
    "                 ['mbugwe','swh_Latn','mgz_Latn'],\n",
    "                 ['naxi','cmn_Latn','nxq_Latn'],\n",
    "                 ['rajbanshi','npi_Deva','rjs_Deva'],\n",
    "                 ['siddi','kan_Knda','mis_Knda'],\n",
    "                 ['tai_nua','shn_Mymr','tdd_Mymr'],\n",
    "                 ['waima','eng_Latn','rro_Latn'],\n",
    "                 ['western_chawma','khm_Khmr','cja_Othr']] #cja_Cham\n",
    "\n",
    "for item in language_data:\n",
    "    language = item[0]\n",
    "    src = item[1]\n",
    "    trg = item[2]\n",
    "\n",
    "    for label in ['train','val','test']:\n",
    "        print(language,label)\n",
    "        if language=='mbugwe' and label=='test': #no test data for mbugwe\n",
    "            continue\n",
    "        prepare_data_for_causal_llm(language+'/'+label+'.src.detok.txt', language+'/'+label+'.trg.detok.txt', \"/Users/laura/llmResearch/all_llm_data/\"+language+'_'+label+'_data.jsonl',src,trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtranslation experiments\n",
    "language = \"saj-Sahu_2024_12_11\"\n",
    "path = \"/Users/laura/S/MT/experiments/Demo_Laura/bt_experiments/\" + language + \"/\"\n",
    "prepare_data_for_causal_llm(path + \"train.src.detok.txt\", path + \"train.trg.detok.txt\", \"/Users/laura/silnlp/scripts/llms/data/bt_experiments/\" + language + \"_train_data.jsonl\",\"saj_Latn\",\"eng_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_for_causal_llm(path + \"test.src.detok.txt\", path + \"test.trg.detok.txt\", \"/Users/laura/silnlp/scripts/llms/data/bt_experiments/\" + language + \"_test_data.jsonl\",\"saj_Latn\",\"eng_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
