{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- Fine tuning NLLB using GaLore \n",
    "### version 1: \n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (22.2.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.2.2\n",
      "    Uninstalling pip-22.2.2:\n",
      "      Successfully uninstalled pip-22.2.2\n",
      "Successfully installed pip-24.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "# Restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/jiaweizzhao/GaLore\n",
      "  Cloning https://github.com/jiaweizzhao/GaLore to /tmp/pip-req-build-g0vyc9tm\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/jiaweizzhao/GaLore /tmp/pip-req-build-g0vyc9tm\n",
      "  Resolved https://github.com/jiaweizzhao/GaLore to commit 2cc66f88cce189e505affbb91042a8e77f5bf4e9\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from galore-torch==1.0) (2.4.1)\n",
      "Requirement already satisfied: transformers in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from galore-torch==1.0) (4.45.1)\n",
      "Requirement already satisfied: bitsandbytes in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from galore-torch==1.0) (0.44.1)\n",
      "Requirement already satisfied: tensorly in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from galore-torch==1.0) (0.8.1)\n",
      "Requirement already satisfied: numpy in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from bitsandbytes->galore-torch==1.0) (2.1.2)\n",
      "Requirement already satisfied: scipy in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from tensorly->galore-torch==1.0) (1.14.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->galore-torch==1.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->galore-torch==1.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->galore-torch==1.0) (12.6.77)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (0.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->galore-torch==1.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (2024.9.11)\n",
      "Requirement already satisfied: requests in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (4.66.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from jinja2->torch->galore-torch==1.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->galore-torch==1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->galore-torch==1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->galore-torch==1.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->galore-torch==1.0) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from sympy->torch->galore-torch==1.0) (1.3.0)\n",
      "Building wheels for collected packages: galore-torch\n",
      "  Building wheel for galore-torch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for galore-torch: filename=galore_torch-1.0-py3-none-any.whl size=14682 sha256=0ee70f3808c0ee20fbdc25d415cf8bb4bb6e4fa80625144be0b6ad9e8ba9f3d2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-edngv0cq/wheels/88/47/b5/ca5f75e9f8a2eef76440b7070f8e82f0099831c3d13ebbe221\n",
      "Successfully built galore-torch\n",
      "Installing collected packages: galore-torch\n",
      "Successfully installed galore-torch-1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-2_hnfkao\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-2_hnfkao\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 1bd604d11c405dfb8b78bda4062d88fc75c17de0\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (2024.9.11)\n",
      "Requirement already satisfied: requests in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (0.20.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers==4.46.0.dev0) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (2024.8.30)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.46.0.dev0-py3-none-any.whl size=9964557 sha256=b83b61d54fea62b2927d494ce9e5de6bf2dbe4627f4807ec02f6d498f8b2e8da\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9_r29grv/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.45.1\n",
      "    Uninstalling transformers-4.45.1:\n",
      "      Successfully uninstalled transformers-4.45.1\n",
      "Successfully installed transformers-4.46.0.dev0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorly in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from tensorly) (2.1.2)\n",
      "Requirement already satisfied: scipy in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from tensorly) (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: flash-attn in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (2.6.3)\n",
      "Requirement already satisfied: torch in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from flash-attn) (2.4.1)\n",
      "Requirement already satisfied: einops in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from flash-attn) (0.8.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: sympy in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (1.13.3)\n",
      "Requirement already satisfied: networkx in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (3.3)\n",
      "Requirement already satisfied: jinja2 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->flash-attn) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U bitsandbytes\n",
    "%pip install git+https://github.com/jiaweizzhao/GaLore\n",
    "%pip install -U git+https://github.com/huggingface/transformers.git\n",
    "%pip install -q -U accelerate\n",
    "%pip install -q -U datasets\n",
    "%pip install -q -U trl\n",
    "%pip install tensorly\n",
    "%pip install -U flash-attn\n",
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/nllb-200-3.3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = 'right' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open('root/credentials.json') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "for key, value in credentials.items():\n",
    "    if not isinstance(value, str):\n",
    "        value = json.dumps(value)  # Convert dicts or lists to string\n",
    "    os.environ[key] = value\n",
    "\n",
    "huggingface_api_key = os.getenv('HUGGINGFACE_API_KEY')\n",
    "aws_access_key = os.getenv('AWS_ACCESS_KEY')\n",
    "aws_secret_key = os.getenv('AWS_SECRET_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "ClearML Task: created new task id=790323c33bab41c698922a60b6f7abc5\n",
      "2024-10-06 22:29:46,012 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.sil.hosted.allegro.ai/projects/96152c47119843d7a026576ef08e348f/experiments/790323c33bab41c698922a60b6f7abc5/output/log\n"
     ]
    }
   ],
   "source": [
    "%pip install -q nbconvert\n",
    "# Import Task from clearml\n",
    "from clearml import Task\n",
    "task = Task.init(project_name=\"HuggingFace Transformers\",\n",
    "    task_name=\"GaLore NLLB\",\n",
    "    output_uri=False) # don’t save any of the models to clearml\n",
    "task.set_parameters_as_dict({ 'save_checkpoints': False })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_inputs': 'translate arb_Arab to acw_Arab: فِي الْبَدْءِ خَلَقَ اللهُ السَّمَاوَاتِ وَالأَرْضَ،', 'completion': 'فِي الْبَدْاية خَلَقَ اللهُ السَّمَاوَاتِ وَالأَرْضَ،\\r\\n'}\n",
      "{'model_inputs': 'translate arb_Arab to acw_Arab: كَانَ قَدْ تَلَقَّنَ طَرِيقَ الرَّبِّ. فَبَدَأَ يَخْطُبُ بِحَمَاسَةٍ شَدِيدَةٍ، وَيُعَلِّمُ الْحَقَائِقَ الْمُخْتَصَّةَ بِيَسُوعَ تَعْلِيماً صَحِيحاً. وَمَعَ أَنَّهُ لَمْ يَكُنْ يَعْرِفُ سِوَى مَعْمُودِيَّةِ يُوحَنَّا،', 'completion': 'وكان يعرف طريق الرب. وصار يتكلم بحماس شديد، ويعلم الحقايق اللي تخص يسوع تعليم صحيح. ورغم أنو كان يعرف معمودية يوحنا بس،\\r\\n'}\n"
     ]
    }
   ],
   "source": [
    "################### read jsonl file into dataset #################################\n",
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "language = 'hejazi'\n",
    "\n",
    "# Initialize a dictionary to hold the lists for each field\n",
    "train = {'model_inputs': [], 'completion': []}\n",
    "val = {'model_inputs': [], 'completion': []}\n",
    "\n",
    "# Open the file and read line by line\n",
    "with open('/root/all_llm_data/'+language+'_train_data.jsonl', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Each line is a complete JSON object\n",
    "        json_object = json.loads(line)\n",
    "        # Append each field to the appropriate list\n",
    "        train['model_inputs'].append(json_object.get('model_inputs', ''))  \n",
    "        train['completion'].append(json_object.get('completion', ''))  \n",
    "\n",
    "# Open the file and read line by line\n",
    "with open('/root/all_llm_data/'+language+'_val_data.jsonl', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Each line is a complete JSON object\n",
    "        json_object = json.loads(line)\n",
    "        # Append each field to the appropriate list\n",
    "        val['model_inputs'].append(json_object.get('model_inputs', ''))  \n",
    "        val['completion'].append(json_object.get('completion', ''))         \n",
    "\n",
    "# Convert the dictionary of lists into a `Dataset`\n",
    "dataset_train = Dataset.from_dict(train)\n",
    "dataset_val = Dataset.from_dict(val)\n",
    "\n",
    "# Create a `DatasetDict` for a train/val split\n",
    "dataset_dict = DatasetDict({'train': dataset_train,'val': dataset_val})\n",
    "\n",
    "# Print the first entry of the dataset to check its structure\n",
    "print(dataset_dict['train'][0])\n",
    "print(dataset_dict['val'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang = \"arb_Arab\"  # Hejazi code or general Arabic code\n",
    "tgt_lang = \"arb_Arab\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e61d7607cb4114b9a9a1d7ee60843c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17582 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135e40af4f1b4170a4e5dccad8677ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [256011, 3292, 28064, 248059, 256011, 202, 762, 248083, 248120, 248085, 28560, 248144, 365, 248151, 248127, 241, 248135, 248129, 248109, 248117, 248135, 248850, 248151, 396, 248109, 248106, 248109, 248187, 248109, 4171, 248176, 5084, 577, 248111, 248109, 1412, 248109, 471, 248151, 141, 248109, 45283, 248109, 248104, 248135, 248670, 248109, 248238, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [256011, 365, 248151, 248127, 241, 248135, 248129, 248109, 248117, 248135, 48614, 396, 248109, 248106, 248109, 248187, 248109, 4171, 248176, 5084, 577, 248111, 248109, 1412, 248109, 471, 248151, 141, 248109, 45283, 248109, 248104, 248135, 248670, 248109, 248238, 248059, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [256011, 3292, 28064, 248059, 256011, 202, 762, 248083, 248120, 248085, 28560, 248144, 451, 248109, 136, 248109, 374, 248109, 248117, 248135, 178, 248109, 248106, 248109, 248187, 577, 248095, 248109, 1513, 248109, 248104, 248151, 6799, 248109, 6051, 577, 248129, 1408, 248075, 365, 248109, 248129, 248109, 248117, 248109, 248314, 248109, 368, 248109, 248247, 248135, 248450, 248176, 248129, 248176, 95, 248151, 248269, 248109, 248111, 248109, 1127, 248109, 248466, 249047, 361, 248109, 248117, 248151, 3435, 248109, 248466, 249047, 248238, 141, 248109, 248127, 248176, 248197, 248109, 248106, 1408, 248111, 248176, 241, 248135, 248269, 248109, 248187, 248109, 1283, 248151, 248187, 248109, 241, 248135, 248111, 248176, 248247, 248135, 248119, 248109, 248457, 577, 248466, 248109, 95, 248151, 248127, 248109, 248142, 248176, 3720, 248109, 178, 248109, 248197, 248135, 248106, 248151, 176441, 248806, 1559, 248109, 248269, 248151, 5811, 248084, 248806, 248075, 141, 248109, 248111, 248109, 248197, 248109, 394, 248109, 248095, 577, 248115, 248176, 237, 248109, 248111, 248135, 368, 248109, 248205, 248176, 248095, 248135, 368, 248109, 248197, 248135, 248104, 248151, 248216, 248176, 236, 248151, 248099, 248109, 248166, 113, 248109, 248197, 248135, 248111, 248176, 685, 248151, 248127, 577, 248466, 248151, 368, 248176, 7479, 248109, 248095, 577, 248084, 248238, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [256011, 132062, 108644, 50074, 220976, 248075, 75439, 195, 23797, 149494, 16031, 24183, 361, 37504, 248238, 141, 5522, 3050, 121911, 1672, 248187, 44351, 178, 6695, 72374, 3720, 154154, 44394, 248075, 7705, 26284, 2899, 248099, 7449, 108644, 2769, 195685, 6028, 368, 7479, 1343, 19251, 248238, 248059, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        examples['model_inputs'], \n",
    "        max_length=1024,  \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    labels = tokenizer(\n",
    "        text_target=examples['completion'], \n",
    "        max_length=1024, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    ).input_ids\n",
    "    \n",
    "    inputs['labels'] = labels\n",
    "    \n",
    "    return inputs \n",
    "\n",
    "# Apply the tokenization function to the dataset\n",
    "tokenized_datasets = dataset_dict.map(\n",
    "    tokenize_function, \n",
    "    batched=True, \n",
    "    remove_columns=['model_inputs', 'completion'] \n",
    ")\n",
    "\n",
    "print(tokenized_datasets['train'][0])\n",
    "print(tokenized_datasets['val'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention with Flash Attention 2 does not support `layer_head_mask`. If you need this feature, please use standard attention.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9fa76e9f1c43b886a4bd54e6181336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-06 22:31:00,160 - clearml.model - INFO - Selected model id: 1ee663f7272943ffa31c4d0a3b4005d1\n",
      "2024-10-06 22:31:05,371 - clearml.model - INFO - Selected model id: 9f7fe73c058147c28f1eabe98028f3bd\n",
      "2024-10-06 22:31:11,147 - clearml.model - INFO - Selected model id: 44632fc281c0481a97cd6b7fb9c02e98\n"
     ]
    }
   ],
   "source": [
    "attn_implementation='flash_attention_2'\n",
    "torch_dtype = torch.float16\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "          model_name, device_map={\"\": 0},  attn_implementation=attn_implementation, torch_dtype=torch_dtype\n",
    ")\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"/root/galore_adamw_nllb_8bit_layerwise_r1024_1e-5_3ep/\",\n",
    "        eval_strategy=\"steps\",   \n",
    "        do_eval=True,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        log_level=\"debug\",\n",
    "        optim=\"galore_adamw_8bit_layerwise\",\n",
    "        optim_args=\"rank=1024, update_proj_gap=100, scale=2\",\n",
    "        optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n",
    "        save_strategy = 'epoch',\n",
    "        logging_steps=200,\n",
    "        learning_rate=1e-5,   \n",
    "        eval_steps=200,\n",
    "        #fp16= False,\n",
    "        bf16= torch.cuda.is_bf16_supported(),\n",
    "        num_train_epochs=1,\n",
    "        warmup_ratio=0.05,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        max_grad_norm=1.0,              \n",
    "        weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3751/3611633092.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer =  Seq2SeqTrainer(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Using auto half precision backend\n",
      "Currently training with a batch size of: 4\n",
      "Activated GaLoRE fine-tuning, depending on your model size and hardware, the training might take a while before starting. Please be patient !\n",
      "***** Running training *****\n",
      "  Num examples = 17,582\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4,396\n",
      "  Number of trainable parameters = 3,344,863,232\n",
      "Automatic ClearML logging enabled.\n",
      "External ClearML Task has been connected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-06 22:31:16,052 - clearml.Task - WARNING - Parameters must be of builtin type (Transformers/accelerator_config[AcceleratorConfig])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected flash_attn version: 2.6.3\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='4396' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  34/4396 00:41 < 1:33:28, 0.78 it/s, Epoch 0.01/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 4\n",
      "  Num examples = 250\n",
      "  Batch size = 4\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 4\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 4\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 4\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 4\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /root/galore_adamw_nllb_8bit_layerwise_r1024_1e-5_3ep/checkpoint-4396\n",
      "/root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/transformers/modeling_utils.py:2774: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "Configuration saved in /root/galore_adamw_nllb_8bit_layerwise_r1024_1e-5_3ep/checkpoint-4396/config.json\n",
      "Configuration saved in /root/galore_adamw_nllb_8bit_layerwise_r1024_1e-5_3ep/checkpoint-4396/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /root/galore_adamw_nllb_8bit_layerwise_r1024_1e-5_3ep/checkpoint-4396/model.safetensors.index.json.\n",
      "tokenizer config file saved in /root/galore_adamw_nllb_8bit_layerwise_r1024_1e-5_3ep/checkpoint-4396/tokenizer_config.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4396, training_loss=1.125884014872446, metrics={'train_runtime': 11029.4398, 'train_samples_per_second': 1.594, 'train_steps_per_second': 0.399, 'total_flos': 3.0464370336281395e+17, 'train_loss': 1.125884014872446, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer =  Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        train_dataset=tokenized_datasets['train'],  \n",
    "        eval_dataset=tokenized_datasets['val'],  \n",
    "        tokenizer=tokenizer,\n",
    "        args=training_arguments,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "s3 = boto3.client('s3',\n",
    "    aws_access_key_id=aws_access_key,\n",
    "    aws_secret_access_key=aws_secret_key,\n",
    ")\n",
    "\n",
    "def upload_file(file_name, bucket, object_name):\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "    try:\n",
    "        s3.upload_file(file_name, bucket, Key=object_name)\n",
    "    except ClientError as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    print(\"Success!\")\n",
    "    return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
