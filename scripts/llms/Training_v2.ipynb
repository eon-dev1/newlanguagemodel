{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- Use this trainer if you need to run models that Unsloth doesn't support\n",
    "### version 2: \n",
    "- Currently the qlora configuration has and tested decoder-only models \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (22.2.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.2.2\n",
      "    Uninstalling pip-22.2.2:\n",
      "      Successfully uninstalled pip-22.2.2\n",
      "Successfully installed pip-24.2\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "# Restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U torch==2.3.0   # nvidia-cudnn-cu12-8.9.2.26 torch-2.3.0 triton-2.3.0\n",
    "%pip install -q -U transformers #==4.43.3\n",
    "%pip install -q -U datasets\n",
    "%pip install -q -U rich\n",
    "%pip install -q -U accelerate \n",
    "%pip install -q -U peft\n",
    "%pip install -q -U bitsandbytes \n",
    "%pip install -q -U optuna\n",
    "%pip install -q -U clearml\n",
    "%pip install -q -U trl \n",
    "%pip install -q -U boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open('credentials.json') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "for key, value in credentials.items():\n",
    "    if not isinstance(value, str):\n",
    "        value = json.dumps(value)  # Convert dicts or lists to string\n",
    "    os.environ[key] = value\n",
    "\n",
    "huggingface_api_key = os.getenv('HUGGINGFACE_API_KEY')\n",
    "aws_access_key = os.getenv('AWS_ACCESS_KEY')\n",
    "aws_secret_key = os.getenv('AWS_SECRET_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "M_lCmYBXE4qH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 16 23:50:42 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.78                 Driver Version: 550.78         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 NVL                On  |   00000000:01:00.0 Off |                   On |\n",
      "| N/A   31C    P0             88W /  400W |                  N/A   |     N/A      Default |\n",
      "|                                         |                        |              Enabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                            |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |                     Memory-Usage |        Vol|      Shared           |\n",
      "|      ID  ID  Dev |                       BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n",
      "|                  |                                  |        ECC|                       |\n",
      "|==================+==================================+===========+=======================|\n",
      "|  0    1   0   0  |           44939MiB / 47488MiB    | 60      0 |  3   0    3    0    3 |\n",
      "|                  |                 3MiB / 65535MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import subprocess\n",
    "# Run nvidia-smi command and capture the output\n",
    "result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE)\n",
    "print(result.stdout.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "ClearML Task: created new task id=d5f3076a63c941869cef8bc31598b5ab\n",
      "2024-09-16 21:51:11,778 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.sil.hosted.allegro.ai/projects/96152c47119843d7a026576ef08e348f/experiments/d5f3076a63c941869cef8bc31598b5ab/output/log\n"
     ]
    }
   ],
   "source": [
    "%pip install -q nbconvert\n",
    "# Import Task from clearml\n",
    "from clearml import Task\n",
    "task = Task.init(project_name=\"HuggingFace Transformers\",\n",
    "    task_name=\"Multilingual LLMs\",\n",
    "    output_uri=False) # don’t save any of the models to clearml\n",
    "task.set_parameters_as_dict({ 'save_checkpoints': False })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inside MIG, Nvidia driver cannot export utilization, pushing fixed value 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_inputs': 'translate arb_Arab to acw_Arab: فِي الْبَدْءِ خَلَقَ اللهُ السَّمَاوَاتِ وَالأَرْضَ،', 'completion': 'فِي الْبَدْاية خَلَقَ اللهُ السَّمَاوَاتِ وَالأَرْضَ،\\r\\n'}\n",
      "{'model_inputs': 'translate arb_Arab to acw_Arab: كَانَ قَدْ تَلَقَّنَ طَرِيقَ الرَّبِّ. فَبَدَأَ يَخْطُبُ بِحَمَاسَةٍ شَدِيدَةٍ، وَيُعَلِّمُ الْحَقَائِقَ الْمُخْتَصَّةَ بِيَسُوعَ تَعْلِيماً صَحِيحاً. وَمَعَ أَنَّهُ لَمْ يَكُنْ يَعْرِفُ سِوَى مَعْمُودِيَّةِ يُوحَنَّا،', 'completion': 'وكان يعرف طريق الرب. وصار يتكلم بحماس شديد، ويعلم الحقايق اللي تخص يسوع تعليم صحيح. ورغم أنو كان يعرف معمودية يوحنا بس،\\r\\n'}\n"
     ]
    }
   ],
   "source": [
    "################### read jsonl file into dataset #################################\n",
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Initialize a dictionary to hold the lists for each field\n",
    "train = {'model_inputs': [], 'completion': []}\n",
    "val = {'model_inputs': [], 'completion': []}\n",
    "\n",
    "language = 'hejazi'\n",
    "\n",
    "# Open the file and read line by line\n",
    "with open('/root/all_llm_data/'+language+'_train_data.jsonl', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Each line is a complete JSON object\n",
    "        json_object = json.loads(line)\n",
    "        # Append each field to the appropriate list\n",
    "        train['model_inputs'].append(json_object.get('model_inputs', ''))  \n",
    "        train['completion'].append(json_object.get('completion', ''))  \n",
    "\n",
    "# Open the file and read line by line\n",
    "with open('/root/all_llm_data/'+language+'_val_data.jsonl', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Each line is a complete JSON object\n",
    "        json_object = json.loads(line)\n",
    "        # Append each field to the appropriate list\n",
    "        val['model_inputs'].append(json_object.get('model_inputs', ''))  \n",
    "        val['completion'].append(json_object.get('completion', ''))         \n",
    "\n",
    "# Convert the dictionary of lists into a `Dataset`\n",
    "dataset_train = Dataset.from_dict(train)\n",
    "dataset_val = Dataset.from_dict(val)\n",
    "\n",
    "# Create a `DatasetDict` for a train/val split\n",
    "dataset_dict = DatasetDict({'train': dataset_train,'val': dataset_val})\n",
    "\n",
    "# Print the first entry of the dataset to check its structure\n",
    "print(dataset_dict['train'][0])\n",
    "print(dataset_dict['val'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "da08306468f34a88a8630ab1f909a036",
      "8235660c0ee54f80a3a57fe23691dc82",
      "6d9af9b5e13549ee8cb99e5dd3263b99",
      "68e9641cc4784c51b22072f0cd6d04ae",
      "51052fedb79c4d07b7cec7cadb63b090",
      "019c7fe403c144498215684eff49004e",
      "43719cb754324422bb02f30fcb7be661",
      "131278d346c94b84b47ca61967a1b248",
      "ec69273a25b14b068a2189e5fea690b4",
      "0c2d9b6681904644961bee1ba5fddc92",
      "c87d1540a3eb4d8a9eae3f1104ef93b3",
      "c58431ad95624d7fbcc9979b8f561a24",
      "09d567d002b6476dacd1515b71c5157d",
      "188fd5504c13486f816bdb7c332a7812",
      "5c36bd910ad4480fb39cf761f802b3dd",
      "d9b5c19eaedf4dbcac01b383a96c309f",
      "e2bbfefc87534b9e85e9a64040b6749a",
      "d9e9c0d7a185402684c8c45109727377",
      "24f0821d311f465c86914c9baa6aaf17",
      "11dcb6341966404b9813b726ca3b064f",
      "c7c256e0479f43419efc43c95291a02c",
      "2b49628931154b52b762390a396ca870",
      "2a8c41e63c2a4b8a8f7f11f24459cf38",
      "51dcae9fc9f34388a54b2d652a70ce4d",
      "55a9a47b7f6f4cdcbde77da5af36fe15",
      "6bc90b3219ff4e50b70f1391c99b2e0c",
      "f1645d9ac2144a61b29d6a0f4347813a",
      "fd0b96a007224d9cae086ab0e9316d0c",
      "728cce2624c349eb8e00a210556a9ff2",
      "c7519a051ecc491da6f039808e542715",
      "f8563a073ee1453c8c02f10bd9a1f694",
      "90eeb4e921ce4929b548a68f12590e81",
      "53ec5140b3a7456baf79975bd73795db",
      "50a9382c1a5548d2804502df7c201265",
      "ee60d8efc3924bb99b3228e91167fb1d",
      "62a50df2ad78430990e8555fd2b68e88",
      "10cd4bd1c43543bab03969482cd5dda6",
      "1b6ad30d26d74cb4b51f1f421ed998d5",
      "43b3801fd8c94a67b4b22f63e4bcaece",
      "c16a491b66bb407e8a2a51a491d5ad0e",
      "735b5a0861024522b30683d42fc584e0",
      "13f1c0e8c770496785d6b50d599973e3",
      "27857f3ce4a745c3b782b975cf653967",
      "a23f40a2177c4384ab6ef9e37b9b6948",
      "985b2fab244b4bec953722db4dad3559",
      "c6a915698b2f4582906338bc20298a1d",
      "eeba6d4f0b8d4c888d47dc2c06bf5f3d",
      "47468b6a3dfe4bc1aad270577aaf14f0",
      "6fa0b8b4b066414dbcc5eaf5178a30c5",
      "64c874ceabd6454497dd8d26da244a78",
      "e89a1b9069a04e05b0554bb02b8edc0c",
      "a8298cae813f4fc1ac3fab4059a83b89",
      "7dc3786aab774a1f8d297464ecff9d06",
      "3b224efcfac44a9ea70411af2663e6b3",
      "ad1520e6f932427597dd4d04b3b2598e",
      "eb26606f40fd4ffdb9bd7cc73328226b",
      "1a9b9a9bcc1f46698ae3cf9969005ed0",
      "00ed9470be7444d9bec90f06de130937",
      "bd23e2ecc12e4ad18c2843c5a5c5d4c3",
      "962848ff58aa42368fd2023cd0024b26",
      "f7c826ff5b1446e0a4590433b6b955a4",
      "95c328f1261f43f5b6449c3d7898508c",
      "4fc3ecd282ea4b988d38115279e13925",
      "8d2d1df552b04e2487c0cbe3c3785456",
      "cc3af33ee18e4dd5b286f40737582bf7",
      "0bdbfad935a74d099e2ed60b5244235a",
      "170aeeff835540098621f8d86c013a47",
      "6cb50f9a64344b53b4106f524b4c4994",
      "31b69f058a34405f87b163ccf936bb4d",
      "cd1113e1e67e4449adbf652015b861dd",
      "c29cc286044645e69abe31aaa79aa067",
      "2458e03c23244c7ea92d62f30165c1fc",
      "6d61882813224be092edeee7b48e9e7e",
      "e5e1798d04404f4da847192646bbedcf",
      "da709da5e40e4df4a8d5213fab496395",
      "cc11716f80ca42c7a76734ec778e4bdc",
      "672bbc04d5cb40e8afa3c2c18c865cdc"
     ]
    },
    "id": "ahe3MSNfE4qI",
    "outputId": "17a2ef40-89b7-450f-b5ae-a501612db0bd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import tqdm as notebook_tqdm\n",
    "from clearml import Task\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, BloomTokenizerFast, BloomForCausalLM\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "max_seq_length = 2048 \n",
    "dtype = torch.bfloat16 # None for auto detection. Float16 for Tesla T4, V100, bfloat16 for Ampere+\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    #bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=dtype\n",
    ")\n",
    "\n",
    "gtp_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules = [\"query_key_vale\",\"dense\",\"sense_h_to_4h\",\"dense_4h_to_h\"],\n",
    "    modules_to_save = [\"embed_tokens\",\"lm_head\"],\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    use_rslora = True,  # Unsloth turned it off since they use custom code\n",
    "    loftq_config = None, # Use LoftQ later\n",
    ")\n",
    "\n",
    "llama_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                          \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    modules_to_save = [\"embed_tokens\",\"lm_head\"],\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    use_rslora = True,   \n",
    "    loftq_config = None, # Use LoftQ later\n",
    ")\n",
    "\n",
    "def load_model():\n",
    "    model_name = \"bigscience/bloom-7b1\"  \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = BloomForCausalLM.from_pretrained(  # AutoModelForCausalLM\n",
    "        model_name,\n",
    "        device_map='auto',\n",
    "        quantization_config=bnb_config\n",
    "    )\n",
    "    return model,tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts }\n",
    "pass\n",
    "\n",
    "def read_data(language,dataset_label):\n",
    "    # Initialize a dictionary to hold the lists for each field\n",
    "    dataset_dict = {'input': [], 'output': [], 'instruction': []}\n",
    "        \n",
    "    # Open the file and read line by line\n",
    "    with open('/root/all_llm_data/'+language+'_'+dataset_label+'_data.jsonl', 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Each line is a complete JSON object\n",
    "            json_object = json.loads(line)\n",
    "            # Append each field to the appropriate list\n",
    "            instruction = json_object.get('model_inputs', '')[:30]\n",
    "            dataset_dict['input'].append(json_object.get('model_inputs', '')[32:]) #remove prompt from input  \n",
    "            dataset_dict['output'].append(json_object.get('completion', '')[:-2]) #remove \\r\\n from end of output\n",
    "            dataset_dict['instruction'].append(instruction)\n",
    "    \n",
    "    # Convert the dictionary of lists into a `Dataset`\n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "    return dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import transformers   \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "def train(model,tokenizer,dataset_train,dataset_val):\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        train_dataset = dataset_train,\n",
    "        formatting_func=formatting_prompts_func, \n",
    "        data_collator=collator,\n",
    "        eval_dataset=dataset_val,\n",
    "        packing=False, \n",
    "        #neftune_noise_alpha = 0.1, \n",
    "        args=SFTConfig(\n",
    "            max_seq_length = max_seq_length,\n",
    "            dataset_num_proc = 2,\n",
    "            dataset_text_field = \"text\",\n",
    "            per_device_train_batch_size=4, # reduce if loss is too high\n",
    "            per_device_eval_batch_size=4,  \n",
    "            gradient_accumulation_steps=4, \n",
    "            warmup_steps=20,   \n",
    "            num_train_epochs=1,\n",
    "            learning_rate=1e-4, # reduce if loss is too high\n",
    "            bf16=True,\n",
    "            logging_steps=10,\n",
    "            optim=\"adamw_torch\",\n",
    "            weight_decay=0.01,\n",
    "            lr_scheduler_type=\"cosine\", \n",
    "            output_dir=\"/root/outputs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    #@title Show current memory stats\n",
    "    gpu_stats = torch.cuda.get_device_properties(0)\n",
    "    start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "    max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "    print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "    print(f\"{start_gpu_memory} GB of memory reserved.\")\n",
    "\n",
    "    trainer_stats = trainer.train()\n",
    "\n",
    "    #@title Show final memory and time stats\n",
    "    used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "    used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "    used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "    lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "    print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "    print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "    print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "    print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "    print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "    print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "s3 = boto3.client('s3',\n",
    "    aws_access_key_id=aws_access_key,\n",
    "    aws_secret_access_key=aws_secret_key,\n",
    ")\n",
    "\n",
    "def upload_file(file_name, bucket, object_name):\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "    try:\n",
    "        s3.upload_file(file_name, bucket, Key=object_name)\n",
    "    except ClientError as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    print(\"Success!\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,tokenizer,language):\n",
    "   # Option 1: Save loRA adapter only, not the full model\n",
    "   model.save_pretrained(\"/root/bloom1_\"+language)\n",
    "   tokenizer.save_pretrained(\"/root/bloom1_\"+language)\n",
    "\n",
    "   files = [\n",
    "     'adapter_config.json',\n",
    "     'adapter_model.safetensors',\n",
    "     #'config.json',\n",
    "     #'generation_config.json',\n",
    "     #'model-00001-of-00002.safetensors',\n",
    "     #'model-00002-of-00002.safetensors',\n",
    "     #'model.safetensors.index.json',\n",
    "     'README.md',\n",
    "     'special_tokens_map.json',\n",
    "     'tokenizer_config.json',\n",
    "     'tokenizer.json']\n",
    "    \n",
    "   for file in files:\n",
    "      print(file)\n",
    "      upload_file(\"/root/bloom1_\" + language + \"/\" + file, \"silnlp\", \\\n",
    "         \"MT/experiments/Demo_Crystal/trained_models/bloom1_\" + language + \\\n",
    "         \"/\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing language: bantawa\n",
      "Loading model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8470c6063ae846259ab58bb9412b416f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7b13f0bf4c4fa29be0c911820bfc3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7687 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading validation data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a9293dee674db49af32ae7226aaba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d23caec00ec4d00a2e1cc89ddc8a5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598adc1e43114717bcd763580f5989d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/7687 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf4608758ac4a6c8c61ba508246fdb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:407: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA H100 NVL MIG 3g.47gb. Max memory = 46.375 GB.\n",
      "44.529 GB of memory reserved.\n",
      "2024-09-16 22:45:31,669 - clearml.Task - WARNING - Parameters must be of builtin type (Transformers_2/accelerator_config[AcceleratorConfig])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 22:01, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.648700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.925300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.799100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.782200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.519000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.236300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.045900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.040600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.977100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.873600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.886400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.873900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.859800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.823900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.785400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.756200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.696800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.697800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.683000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.658600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.668600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.623800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.653100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.668300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.583900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.626500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.651200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.615300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.569900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.591300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.550300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.607200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.550800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.569300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.493100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.606100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1326.1701 seconds used for training.\n",
      "22.1 minutes used for training.\n",
      "Peak reserved memory = 44.529 GB.\n",
      "Peak reserved memory for training = 0.0 GB.\n",
      "Peak reserved memory % of max memory = 96.019 %.\n",
      "Peak reserved memory for training % of max memory = 0.0 %.\n",
      "Saving model adapter for bantawa\n",
      "adapter_config.json\n",
      "Success!\n",
      "adapter_model.safetensors\n",
      "Success!\n",
      "README.md\n",
      "Success!\n",
      "special_tokens_map.json\n",
      "Success!\n",
      "tokenizer_config.json\n",
      "Success!\n",
      "tokenizer.json\n",
      "Success!\n",
      "Processing language: tai_nua\n",
      "Loading model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d897132790fa456a8aabeaf9b6aaa528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c330e2df2e4677a4cedb6af59342e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7429 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading validation data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec4b0ab006d4f03bf420de6ed94f72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aea58820a90441d8804ec3c2690dc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fa5fcf62f24934bfa3afa307101614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/7429 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c92e4d682bf49a28f2bc0f6dc2cb139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:407: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA H100 NVL MIG 3g.47gb. Max memory = 46.375 GB.\n",
      "44.529 GB of memory reserved.\n",
      "2024-09-16 23:14:13,087 - clearml.Task - WARNING - Parameters must be of builtin type (Transformers_3/accelerator_config[AcceleratorConfig])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/464 : < :, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m model \u001b[39m=\u001b[39m prepare_model_for_kbit_training(model)\n\u001b[1;32m     29\u001b[0m model \u001b[39m=\u001b[39m get_peft_model(model, gtp_config)   \u001b[39m# llama_config, gtp_config \u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m model \u001b[39m=\u001b[39m train(model,tokenizer,dataset_train, dataset_val)\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSaving model adapter for \u001b[39m\u001b[39m{\u001b[39;00mlanguage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m save_model(model,tokenizer,language)\n",
      "Cell \u001b[0;32mIn[8], line 46\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, tokenizer, dataset_train, dataset_val)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGPU = \u001b[39m\u001b[39m{\u001b[39;00mgpu_stats\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m. Max memory = \u001b[39m\u001b[39m{\u001b[39;00mmax_memory\u001b[39m}\u001b[39;00m\u001b[39m GB.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mstart_gpu_memory\u001b[39m}\u001b[39;00m\u001b[39m GB of memory reserved.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m trainer_stats \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     48\u001b[0m \u001b[39m#@title Show final memory and time stats\u001b[39;00m\n\u001b[1;32m     49\u001b[0m used_memory \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mmax_memory_reserved() \u001b[39m/\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m/\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m/\u001b[39m \u001b[39m1024\u001b[39m, \u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:450\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneftune_noise_alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    448\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trl_activate_neftune(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel)\n\u001b[0;32m--> 450\u001b[0m output \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtrain(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    452\u001b[0m \u001b[39m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneftune_noise_alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1939\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1940\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1941\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1942\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1943\u001b[0m     )\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   2281\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/transformers/trainer.py:3318\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   3317\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3318\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   3320\u001b[0m \u001b[39mdel\u001b[39;00m inputs\n\u001b[1;32m   3321\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtorch_empty_cache_steps \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3323\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtorch_empty_cache_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   3324\u001b[0m ):\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/transformers/trainer.py:3363\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3362\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 3363\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   3364\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3366\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[39mreturn\u001b[39;00m model_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_to_fp32(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/accelerate/utils/operations.py:787\u001b[0m, in \u001b[0;36mconvert_to_fp32\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_is_fp16_bf16_tensor\u001b[39m(tensor):\n\u001b[1;32m    782\u001b[0m     \u001b[39mreturn\u001b[39;00m (is_torch_tensor(tensor) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mand\u001b[39;00m tensor\u001b[39m.\u001b[39mdtype \u001b[39min\u001b[39;00m (\n\u001b[1;32m    783\u001b[0m         torch\u001b[39m.\u001b[39mfloat16,\n\u001b[1;32m    784\u001b[0m         torch\u001b[39m.\u001b[39mbfloat16,\n\u001b[1;32m    785\u001b[0m     )\n\u001b[0;32m--> 787\u001b[0m \u001b[39mreturn\u001b[39;00m recursively_apply(_convert_to_fp32, tensor, test_type\u001b[39m=\u001b[39;49m_is_fp16_bf16_tensor)\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/accelerate/utils/operations.py:119\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[39mreturn\u001b[39;00m honor_type(\n\u001b[1;32m    109\u001b[0m         data,\n\u001b[1;32m    110\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m         ),\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(data)(\n\u001b[0;32m--> 119\u001b[0m         {\n\u001b[1;32m    120\u001b[0m             k: recursively_apply(\n\u001b[1;32m    121\u001b[0m                 func, v, \u001b[39m*\u001b[39margs, test_type\u001b[39m=\u001b[39mtest_type, error_on_other_type\u001b[39m=\u001b[39merror_on_other_type, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    122\u001b[0m             )\n\u001b[1;32m    123\u001b[0m             \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    124\u001b[0m         }\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    126\u001b[0m \u001b[39melif\u001b[39;00m test_type(data):\n\u001b[1;32m    127\u001b[0m     \u001b[39mreturn\u001b[39;00m func(data, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/accelerate/utils/operations.py:120\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[39mreturn\u001b[39;00m honor_type(\n\u001b[1;32m    109\u001b[0m         data,\n\u001b[1;32m    110\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m         ),\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(data)(\n\u001b[1;32m    119\u001b[0m         {\n\u001b[0;32m--> 120\u001b[0m             k: recursively_apply(\n\u001b[1;32m    121\u001b[0m                 func, v, \u001b[39m*\u001b[39;49margs, test_type\u001b[39m=\u001b[39;49mtest_type, error_on_other_type\u001b[39m=\u001b[39;49merror_on_other_type, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    122\u001b[0m             )\n\u001b[1;32m    123\u001b[0m             \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    124\u001b[0m         }\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    126\u001b[0m \u001b[39melif\u001b[39;00m test_type(data):\n\u001b[1;32m    127\u001b[0m     \u001b[39mreturn\u001b[39;00m func(data, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/accelerate/utils/operations.py:127\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(data)(\n\u001b[1;32m    119\u001b[0m         {\n\u001b[1;32m    120\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m         }\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    126\u001b[0m \u001b[39melif\u001b[39;00m test_type(data):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m func(data, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    128\u001b[0m \u001b[39melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    129\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported types (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) passed to `\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m`. Only nested list/tuple/dicts of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mobjects that are valid for `\u001b[39m\u001b[39m{\u001b[39;00mtest_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` should be passed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m     )\n",
      "File \u001b[0;32m~/.clearml/venvs-builds/3.10/lib/python3.10/site-packages/accelerate/utils/operations.py:779\u001b[0m, in \u001b[0;36mconvert_to_fp32.<locals>._convert_to_fp32\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_convert_to_fp32\u001b[39m(tensor):\n\u001b[0;32m--> 779\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49mfloat()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. "
     ]
    }
   ],
   "source": [
    "#languages = ['balti','bana','bantawa','borong','gutob_gadaba','hejazi','kisar','konda_dora','kuvi','kwaraae','limbum','mbugwe','naxi','rajbanshi','siddi','tai_nua','waima','western_chawma']\n",
    "\n",
    "languages = ['bantawa','tai_nua']\n",
    "\n",
    "for language in languages:\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Processing language: {language}\")\n",
    "\n",
    "    print(\"Loading model\")\n",
    "    model,tokenizer = load_model()\n",
    "    EOS_TOKEN = tokenizer.eos_token or \"<|endoftext|>\" \n",
    "\n",
    "    print(\"Reading training data\")\n",
    "    dataset_train = read_data(language,\"train\")\n",
    "\n",
    "    print(\"Reading validation data\")\n",
    "    dataset_val = read_data(language,\"val\")\n",
    "\n",
    "    if language != \"mbugwe\": # no test data for mbugwe\n",
    "        print(\"Reading test data\")\n",
    "        dataset_test = read_data(language,\"test\")\n",
    "\n",
    "    print(\"Training\")\n",
    "    # Training setup \n",
    "    collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)  # causal language modeling\n",
    "\n",
    "    model.gradient_checkpointing_enable()    # Memory-efficient training\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, gtp_config)   # llama_config, gtp_config \n",
    "\n",
    "    model = train(model,tokenizer,dataset_train, dataset_val)\n",
    "\n",
    "    print(f\"Saving model adapter for {language}\")\n",
    "    save_model(model,tokenizer,language)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
