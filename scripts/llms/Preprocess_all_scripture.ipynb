{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all bibles\n",
    "# Takes about 3 minutes\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm.notebook import tqdm\n",
    "from iso639 import Lang\n",
    "\n",
    "path = \"/Users/laura/llmResearch/scripture/\"\n",
    "files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "print('Before processing - number of Bibles:',len(files))\n",
    "\n",
    "bibles = []\n",
    "languages = []\n",
    "filepaths = []\n",
    "\n",
    "# Don't include the languages we want to test on\n",
    "test_languages = ['bft','bcw','bap','ksr','gbj','acw','kje','kfc','kxv','kwf','lmp','mgz','nxq','rjs','kan','tdd','rro','cja']\n",
    "\n",
    "# Cache previously seen iso-3 language codes (speeds it up considerably)\n",
    "language_codes = {}\n",
    "# Exceptions\n",
    "language_codes['pou'] = 'poc'\n",
    "language_codes['sgjj'] = 'sgj' # typo\n",
    "language_codes['in'] = 'ind' # best guess - indonesian\n",
    "language_codes['wra'] = 'wra'\n",
    "language_codes['pltA'] = 'plt'\n",
    "language_codes['pltB'] = 'plt'\n",
    "language_codes['thfL'] = 'thf'\n",
    "language_codes['bapL'] = 'bap'\n",
    "language_codes['dud'] = 'dud'\n",
    "language_codes['eng'] = 'Latn'\n",
    "language_codes['deu'] = 'Latn'\n",
    "\n",
    "for file_name in tqdm(files):\n",
    "  with open(path + file_name,\"r\",encoding=\"utf-8\") as file:\n",
    "    lines = [i[:-1] for i in file.readlines()] # remove ending newline\n",
    "\n",
    "  if len([i for i in lines if i!='']) == 0: # skip empty bibles\n",
    "    continue\n",
    "\n",
    "  if len(lines) != 41899: # only use full bibles (previous calculations show only about 7% of bibles aren't full)\n",
    "    continue\n",
    "\n",
    "  # Find iso-3 language code for each language\n",
    "  language = file_name[:file_name.find('-')]\n",
    "  if language in language_codes:\n",
    "    iso_code = language_codes[language]\n",
    "  else:\n",
    "    try:\n",
    "      iso_code = Lang(language).pt3\n",
    "    except: # can't find language code\n",
    "      iso_code = ''\n",
    "    language_codes[language] = iso_code\n",
    "\n",
    "  if iso_code not in test_languages:\n",
    "    languages.append(iso_code)\n",
    "    bibles.append(lines)\n",
    "    filepaths.append(file_name)\n",
    "\n",
    "print('After processing - final number of Bibles:',len(bibles))\n",
    "print('Number of unknown languages:',len([i for i in languages if i==''])) # number of unknown language codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need to run if you want to automatically generate script codes for below - otherwise skip\n",
    "# Before running, need to have run previous code to get a list of scripts not_in_dict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "iso_scripts = pd.read_csv('data/iso_scripts.csv')\n",
    "\n",
    "for script in set(not_in_dict):\n",
    "  code = list(iso_scripts[iso_scripts['Alias']==script]['Code'])[0]\n",
    "  print(\"script_codes['\"+script.upper()+\"'] = '\" + code + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the script for each Bible\n",
    "# Takes about 2.5 minutes\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/Users/laura/silnlp/silnlp/common\"))\n",
    "from script_utils import get_script\n",
    "\n",
    "#https://en.wikipedia.org/wiki/ISO_15924\n",
    "# also can generate this automatically using code above\n",
    "script_codes = {}\n",
    "script_codes['CYRILLIC'] = 'Cyrl'\n",
    "script_codes['LATIN'] = 'Latn'\n",
    "script_codes['KANNADA'] = 'Knda'\n",
    "script_codes['GUJARATI'] = 'Gujr'\n",
    "script_codes['ARABIC'] = 'Arab'\n",
    "script_codes['BENGALI'] = 'Beng'\n",
    "script_codes['DEVANAGARI'] = 'Deva'\n",
    "script_codes['ETHIOPIC'] = 'Ethi'\n",
    "script_codes['GEORGIA'] = 'Geor'\n",
    "script_codes['GREEK'] = 'Grek'\n",
    "script_codes['GURMUKHI'] = 'Guru'\n",
    "script_codes['HANGUL'] = 'Hang'\n",
    "script_codes['HEBREW'] = 'Hira'\n",
    "script_codes['KHMER'] = 'Khmr'\n",
    "script_codes['LAO'] = 'Laoo'\n",
    "script_codes['MALAYALAM'] = 'Mlym'\n",
    "script_codes['MYANMAR'] = 'Mymr'\n",
    "script_codes['ORIYA'] = 'Orya'\n",
    "script_codes['SINHALA'] = 'Sinh'\n",
    "script_codes['TAMIL'] = 'Taml'\n",
    "script_codes['TELUGU'] = 'Telu'\n",
    "script_codes['THAI'] = 'Thai'\n",
    "script_codes['TIBETAN'] = 'Tibt'\n",
    "script_codes['VAI'] = 'Vaii'\n",
    "script_codes['TAI_THAM'] = 'Lana'\n",
    "script_codes['TIFINAGH'] = 'Tfng'\n",
    "script_codes['GEORGIAN'] = 'Geor'\n",
    "script_codes['LISU'] = 'Lisu'\n",
    "script_codes['HIRAGANA'] = 'Hira'\n",
    "script_codes['SYRIAC'] = 'Syrc'\n",
    "script_codes['COMMON'] = 'Zyyy'\n",
    "script_codes['MONGOLIAN'] = 'Mong'\n",
    "script_codes['CANADIAN_ABORIGINAL'] = 'Cans'\n",
    "script_codes['KAYAH_LI'] = 'Kali'\n",
    "script_codes['LIMBU'] = 'Limb'\n",
    "script_codes['HAN'] = 'Hani'\n",
    "\n",
    "llm_tags = []\n",
    "not_in_dict = []\n",
    "for i in tqdm(range(len(bibles))):\n",
    "  not_empty = [k for k in bibles[i] if k != ''] # find non-empty verses\n",
    "  script = get_script(''.join(not_empty[:10])) # look at 10 verses to determine script\n",
    "  if script.upper() in script_codes:\n",
    "    llm_tags.append(languages[i] + '_' + script_codes[script.upper()])\n",
    "  else:\n",
    "    not_in_dict.append(script)\n",
    "    llm_tags.append(languages[i] + '_Othr')\n",
    "\n",
    "print('scripts not in dictionary',set(not_in_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count up how many versions of each verse there are\n",
    "# Takes about 22 minutes\n",
    "\n",
    "num_verses = []\n",
    "for verse in tqdm(range(41899)):\n",
    "  num_verses.append(len([i for i in bibles if i[verse] != '']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of versions of each verse there are\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(num_verses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we were to consider every pair of verses in every language, how many pairs of verses would we have?\n",
    "\n",
    "total = sum([i*(i-1) for i in num_verses])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many Bibles are in each script\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "for llm_tag in tqdm(llm_tags):\n",
    "  script = llm_tag.split('_')[1]\n",
    "  counter[script]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot sources calculated in Select_pivot_languages.ipynb\n",
    "pivot_sources = ['en-NIV11R','es-DHHE','ko-RNKSV','fr-LBS21','cmn-CU2010S','ru-NRT23','swh-MFT_2023_11_11','hi-HINOVBSI','npi-SNHB','id-BIMK']\n",
    "pivot_sources = [i + '.txt' for i in pivot_sources]\n",
    "\n",
    "pivot_indices = [filepaths.index(pivot_source) for pivot_source in pivot_sources]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many pairs of verses are there with ten pivot languages?\n",
    "\n",
    "total = sum([(i-10)*10 for i in num_verses])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pivot_indices = [i for i in range(len(bibles)) if i not in pivot_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/all_scripture_llm_input.jsonl', 'w') as output_file:\n",
    "  for verse in tqdm(range(41899)):\n",
    "    pivot_verses = [str(verse) + \" \" + llm_tags[j] + \": \" + bibles[j][verse].strip() for j in pivot_indices if bibles[j][verse] != '']\n",
    "    non_pivot_verses = [str(verse) + \" \" + llm_tags[j] + \": \" + bibles[j][verse].strip() for j in non_pivot_indices if bibles[j][verse] != '']\n",
    "\n",
    "    output_file.write('\\n'.join(pivot_verses + non_pivot_verses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
