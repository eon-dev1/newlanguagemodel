{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USFM marker preservation\n",
    "* Extract footnotes and put them at the end\n",
    "* Extract each instance of a marker and record its index\n",
    "* Tokenize source sentences and match each marker to surrounding tokens based on their original indices\n",
    "* Train aligner on all training data + translation, align translation to source\n",
    "* Reinsert marker instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "'''Define project values'''\n",
    "pair = \"\"\n",
    "project = \"\"\n",
    "file_suffix = \"\"\n",
    "trg_project = \"\"\n",
    "trg_file_suffix = \"\"\n",
    "\n",
    "book = \"MAT\"\n",
    "book_name = f\"41{book}\"\n",
    "src_fpath = Path(f\"test_S/Paratext/projects/{project}/{book_name}{file_suffix}.SFM\")\n",
    "aligner = \"eflomal\"\n",
    "pair_book_dir = Path(f\"zzz_PN_KTs/{pair}/{book}\")\n",
    "align_path = pair_book_dir / f\"{book_name}_sym-align_{aligner}.txt\"\n",
    "out_fpath = pair_book_dir / f\"{book_name}{trg_file_suffix}_out.SFM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine.corpora import FileParatextProjectSettingsParser, UsfmFileText # UsfmTokenizer\n",
    "# from machine.tokenization import LatinWordTokenizer\n",
    "\n",
    "src_settings = FileParatextProjectSettingsParser(src_fpath.parent).parse()\n",
    "src_file_text = UsfmFileText(\n",
    "    src_settings.stylesheet,\n",
    "    src_settings.encoding,\n",
    "    book,\n",
    "    src_fpath,\n",
    "    src_settings.versification,\n",
    "    include_markers=True, # F/T gives notes their own rows, F/F gives just the main text, T/F gives one ref per verse and all markers are inline\n",
    "    include_all_text=True, # T/T includes all intro and section titles (as does F/T), all other notes/markers inline\n",
    "    project=src_settings.name,\n",
    ")\n",
    "\n",
    "sentences = []\n",
    "vrefs = []\n",
    "for sent in src_file_text:\n",
    "    if len(sent.ref.path) > 0 and sent.ref.path[-1].name == \"rem\":\n",
    "        continue\n",
    "    sentences.append(sent.text.strip())\n",
    "    vrefs.append(sent.ref)\n",
    "\n",
    "# for ref, sent in zip(vrefs, sentences):\n",
    "#     print(ref, sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only deal with paragraph markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine.corpora import UsfmTokenizer, UsfmTokenType, UsfmStyleType\n",
    "# TODO: would it be easier to always use StyleType (for UsfmTags) vs TokenType (for UsfmTokens)?\n",
    "\n",
    "'''Parse sentences'''\n",
    "tokenizer = UsfmTokenizer(src_settings.stylesheet)\n",
    "sentence_toks = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "to_delete = [\"fig\"]\n",
    "inline_markers = []\n",
    "text_only_sents = [\"\" for _ in sentence_toks]\n",
    "for i, toks in enumerate(sentence_toks):\n",
    "    ignore_scope = None\n",
    "    char_scope = None\n",
    "    for j, tok in enumerate(toks): # POSSIBLE TYPES: TEXT, PARAGRAPH, CHARACTER, NOTE, END\n",
    "        if ignore_scope is not None:\n",
    "            if tok.type == UsfmTokenType.END and tok.marker[:-1] == ignore_scope.marker:\n",
    "                ignore_scope = None\n",
    "        elif tok.type == UsfmTokenType.NOTE or (tok.type == UsfmTokenType.CHARACTER and tok.marker in to_delete):\n",
    "            ignore_scope = tok\n",
    "        elif tok.type in [UsfmTokenType.PARAGRAPH, UsfmTokenType.CHARACTER, UsfmTokenType.END]:\n",
    "            inline_markers.append((i, len(text_only_sents[i]), tok.to_usfm()))\n",
    "        elif tok.type == UsfmTokenType.TEXT:\n",
    "            text_only_sents[i] += tok.text\n",
    "\n",
    "# print(\"sent_idx, orig_idx, marker\")\n",
    "# for marker in inline_markers:\n",
    "#     print(marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine.corpora import FileParatextProjectSettingsParser, UsfmFileText\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "'''Translate sentences'''\n",
    "trg_sents = []\n",
    "src_tokens = []\n",
    "trg_tokens = []\n",
    "alignment_matrices = []\n",
    "\n",
    "# TODO: verify sentences\n",
    "for sent, sent_toks in zip(trg_sents, trg_tokens):\n",
    "    print(\"\".join(sent_toks).replace(\"_\", \" \") == sent)\n",
    "\n",
    "'''Need to match markers to their closest token idx'''\n",
    "def get_toks_after_sequences(sequences: List[Tuple]) -> List[int]:\n",
    "    return []\n",
    "\n",
    "toks_after_markers = get_toks_after_sequences(inline_markers)\n",
    "\n",
    "for ref, sent in zip(vrefs,trg_sents):\n",
    "    print(ref, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from silnlp.common.corpus import load_corpus\n",
    "\n",
    "'''Decide where to reinsert markers'''\n",
    "trg_toks_after_markers = []\n",
    "matrix: List[List[bool]]\n",
    "for marker, idx, matrix in zip(inline_markers, toks_after_markers, alignment_matrices):\n",
    "    trg_toks_after_markers.append(matrix[idx].index(True))\n",
    "\n",
    "print(toks_after_markers)\n",
    "print(trg_toks_after_markers)\n",
    "print(len(trg_toks_after_markers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: right now, half the word for the insertion order is done when to_insert is filled out, and the other half is done when the markers are\n",
    "being inserted (with reverse). Since there there's already funky stuff going on in the order of the markers in to_insert (for disambiguation \n",
    "for the same insertion idx), it would make more sense to just do all the ordering when to_insert is being filled out, i.e. the order of a list\n",
    "in to_insert is the order they need to be inserted in\n",
    "on the other hand, the current way might be more human-readable\n",
    "'''\n",
    "\n",
    "'''Reinsert markers'''\n",
    "to_insert = [[] for _ in vrefs]\n",
    "\n",
    "# Collect the markers to be inserted\n",
    "for i, (mark, next_trg_tok) in enumerate(zip(inline_markers, trg_toks_after_markers)):\n",
    "    sent_idx, _, marker = mark\n",
    "    insert_idx = trg_word_tok_ranges[sent_idx][next_trg_tok].start\n",
    "\n",
    "    # figure out the order of the markers in the sentence to handle ambiguity for directly adjacent markers\n",
    "    insert_place = 0\n",
    "    while insert_place < len(to_insert[sent_idx]) and to_insert[sent_idx][insert_place][0] <= insert_idx:\n",
    "        insert_place += 1\n",
    "\n",
    "    to_insert[sent_idx].insert(insert_place, (insert_idx, marker))\n",
    "\n",
    "'''create rows for each paragraph marker and insert character markers back into text'''\n",
    "# Construct rows to update the USFM file with\n",
    "rows = []\n",
    "for sent_idx, (ref, trg_sent) in enumerate(zip(vrefs, trg_sents)):\n",
    "    row_texts = []\n",
    "    attach_to_prev = False # TODO: better name\n",
    "    prev_is_end = False # hacky\n",
    "    for insert_idx, marker in reversed(to_insert[sent_idx]):\n",
    "        is_char_marker = src_settings.stylesheet.get_tag(marker.strip(\" \\\\+*\")).style_type == UsfmStyleType.CHARACTER\n",
    "        row_text = (marker if is_char_marker else \"\") \\\n",
    "                    + (\" \" if \"*\" in marker and insert_idx < len(trg_sent) and trg_sent[insert_idx].isalpha() else \"\") \\\n",
    "                    + trg_sent[insert_idx:]\n",
    "\n",
    "        if attach_to_prev:\n",
    "            # don't want a space before end marker\n",
    "            if prev_is_end and len(row_text) > 0 and row_text[-1] == \" \": # hacky\n",
    "                row_text = row_text[:-1]\n",
    "            # append text segments instead of creating a new one since previous segment (really the next segment bc iterating backwards) is not its own paragraph\n",
    "            row_texts[0] = row_text + row_texts[0]\n",
    "        else:\n",
    "            row_texts.insert(0, row_text)\n",
    "\n",
    "        # only paragraph markers get their own rows, so all segments split by character markers and their end markers need to be rejoined\n",
    "        attach_to_prev = is_char_marker\n",
    "        prev_is_end = \"*\" in marker\n",
    "        trg_sent = trg_sent[:insert_idx]\n",
    "\n",
    "    # do the same as above with the text at the beginning of the verse\n",
    "    if attach_to_prev:\n",
    "        if prev_is_end and len(trg_sent) > 0 and trg_sent[-1] == \" \": # hacky\n",
    "            trg_sent = trg_sent[:-1]\n",
    "        row_texts[0] = trg_sent + row_texts[0]\n",
    "    else:\n",
    "        rows.append(([ref], trg_sent))\n",
    "\n",
    "    for row_text in row_texts:\n",
    "        rows.append(([ref], row_text))\n",
    "\n",
    "print(len(rows))\n",
    "for ref, sent in rows:\n",
    "    print(ref, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine.corpora import UpdateUsfmParserHandler, parse_usfm, UsfmParserState, UpdateUsfmBehavior\n",
    "\n",
    "class ParagraphUpdateUsfmParserHandler(UpdateUsfmParserHandler):\n",
    "    def _collect_tokens(self, state: UsfmParserState) -> None:\n",
    "        self._tokens.extend(self._new_tokens)\n",
    "        self._new_tokens.clear()\n",
    "        while self._token_index <= state.index + state.special_token_count:\n",
    "            if state.tokens[self._token_index].type == UsfmTokenType.PARAGRAPH and state.tokens[self._token_index].marker != \"rem\":\n",
    "                num_text = 0\n",
    "                rem_offset = 0\n",
    "                for i in range(len(self._tokens) - 1, -1, -1):\n",
    "                    if self._tokens[i].type == UsfmTokenType.TEXT:\n",
    "                        num_text += 1\n",
    "                    elif self._tokens[i].type == UsfmTokenType.PARAGRAPH and self._tokens[i].marker == \"rem\":\n",
    "                        rem_offset += num_text + 1\n",
    "                        num_text = 0\n",
    "                    else:\n",
    "                        break\n",
    "                if num_text >= 2:\n",
    "                    self._tokens.insert(-(rem_offset + num_text - 1), state.tokens[self._token_index])\n",
    "                    self._token_index += 1\n",
    "                    break # should this be continue instead? what situations are there where \n",
    "            self._tokens.append(state.tokens[self._token_index])\n",
    "            self._token_index += 1\n",
    "\n",
    "'''Update USFM and write out'''\n",
    "# preserve_whitespace=True doesn't change anything with markers on newlines but it does take care of the \\vp\\*vp somehow\n",
    "with open(src_fpath, encoding=\"utf-8-sig\") as f:\n",
    "    usfm = f.read()\n",
    "handler = ParagraphUpdateUsfmParserHandler(rows, behavior=UpdateUsfmBehavior.PREFER_NEW)\n",
    "parse_usfm(usfm, handler, src_settings.stylesheet, src_settings.versification, preserve_whitespace=False)\n",
    "usfm_out = handler.get_usfm(src_settings.stylesheet)\n",
    "\n",
    "with out_fpath.open(\"w\", encoding=src_settings.encoding) as f:\n",
    "    f.write(usfm_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
