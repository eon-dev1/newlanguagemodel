{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "# import jaro\n",
    "\n",
    "from machine.corpora import FileParatextProjectSettingsParser, UsfmFileText\n",
    "from machine.tokenization import WhitespaceTokenizer, LatinWordTokenizer\n",
    "\n",
    "class WhitespaceSlashTokenizer(WhitespaceTokenizer):\n",
    "    def _is_whitespace(self, c: str) -> bool:\n",
    "        return super()._is_whitespace(c) or c == \"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Code from https://github.com/richmilne/JaroWinkler/blob/master/jaro/jaro.py'''\n",
    "\n",
    "def jaro(s1, s2):\n",
    "    # s1 is always the shorter string\n",
    "    if len(s2) < len(s1):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    if len(s1) == 0:\n",
    "        print(\"empty sequence\")\n",
    "        print(s1)\n",
    "        print(s2)\n",
    "        return 0, 0\n",
    "\n",
    "    search_range = max((len(s2) // 2) - 1, 0)\n",
    "    matched1 = [0] * len(s1)\n",
    "    matched2 = [0] * len(s2)\n",
    "    num_matches = 0\n",
    "\n",
    "    for i, char in enumerate(s1):\n",
    "        for j in range(max(i - search_range, 0), min(i + search_range, len(s2) - 1) + 1):\n",
    "            if not matched2[j] and char == s2[j]:\n",
    "                matched1[i] = matched2[j] = 1\n",
    "                num_matches += 1\n",
    "                break\n",
    "    \n",
    "    if num_matches == 0:\n",
    "        print(\"no matches\")\n",
    "        print(s1)\n",
    "        print(s2)\n",
    "        return 0, 0\n",
    "\n",
    "    # number of matched tokens in s1 such that if it is the ith matched token, the the ith matched token in s2 (in linear order) is not what it was matched with\n",
    "    # this number divided by 2 is the number of transpositions\n",
    "    half_transposes = 0\n",
    "    j = 0\n",
    "    for i, matched in enumerate(matched1):\n",
    "        if not matched:\n",
    "            continue\n",
    "        while not matched2[j]:\n",
    "            j += 1\n",
    "        if s1[i] != s2[j]:\n",
    "            half_transposes += 1\n",
    "        j += 1\n",
    "\n",
    "    dist = (\n",
    "        num_matches / len(s1)\n",
    "        + num_matches / len(s2)\n",
    "        + (num_matches - half_transposes // 2) / num_matches\n",
    "        ) / 3\n",
    "    return dist, half_transposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold sentences: constructed \"goal\" files, ideally based on source project but typically based on target project\n",
    "# predicted sentences: translated output, based on source project\n",
    "project_path = Path(\"test_S/Paratext/projects/DHH94\")\n",
    "# difference bw goal file and orig trg for tpi_aps is that embeds are moved to the end of their ScriptureRefs\n",
    "book = \"PSA\"\n",
    "chapters = {9, 10}\n",
    "gold_file_path = Path(\"zzz_USFM_eval/aa_gold_standard/spa_zpu_19PSAzpuAT_9_10.SFM\")\n",
    "pred_file_path = Path(\"zzz_USFM_eval/spa_zpu/19PSA_eflomal.SFM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no matches\n",
      "['Salmo', '10', '(9b)']\n",
      "['Biaschga,', 'q1', 'Xanaꞌ,', 'q1', 'bi', 'udegonoꞌ', 'dan', 'llun', 'beꞌnn', 'naꞌch', 'kaꞌ,', 'q1', 'ke', 'll‐lantegare,', 'q1', 'bwechga', 'kaꞌ', 'gonoꞌ', 'ke', \"be'nn\", \"ka'\", 'bi', 'nombiaꞌ', 'rwen,', 'q1', 'gan', 'lliw', 'llonoꞌ', 'yel', 'korchisen.']\n",
      "no matches\n",
      "['Yelwill-llo', 'Diozen', \"nench'na\", \"gakrene'e\", \"lli'on\"]\n",
      "['Bechjga', 'ke', 'lleb', 'beꞌnn', 'ki,', 'q1', 'Xanaꞌ,', 'q1', 'benchga', 'ke', 'chejnieꞌ', 'beꞌnnki,', 'q1', 'leke', 'naken', 'nak', \"ake'\", 'zerawze', 'beꞌnn', 'naꞌche.']\n"
     ]
    }
   ],
   "source": [
    "settings = FileParatextProjectSettingsParser(project_path).parse()\n",
    "gold_file_text = UsfmFileText(\n",
    "    settings.stylesheet,\n",
    "    settings.encoding,\n",
    "    book,\n",
    "    gold_file_path,\n",
    "    settings.versification,\n",
    "    include_markers=True,\n",
    "    include_all_text=True,\n",
    "    project=settings.name,\n",
    ")\n",
    "pred_file_text = UsfmFileText(\n",
    "    settings.stylesheet,\n",
    "    settings.encoding,\n",
    "    book,\n",
    "    pred_file_path,\n",
    "    settings.versification,\n",
    "    include_markers=True,\n",
    "    include_all_text=True,\n",
    "    project=settings.name,\n",
    ")\n",
    "\n",
    "'''Preprocess'''\n",
    "# have to iterate over individually at first because gold standard file only contains the specific chapters\n",
    "ignore = [\"r\", \"rem\"]\n",
    "all_vrefs = []\n",
    "gold_sents = []\n",
    "for gs in gold_file_text:\n",
    "    if (len(gs.ref.path) > 0 and gs.ref.path[-1].name in ignore) or gs.ref.chapter_num not in chapters:\n",
    "        continue\n",
    "    all_vrefs.append(gs.ref)\n",
    "    gold_sents.append(gs.text)\n",
    "pred_sents = []\n",
    "pv = []\n",
    "for ps in pred_file_text:\n",
    "    if (len(ps.ref.path) > 0 and ps.ref.path[-1].name in ignore) or ps.ref.chapter_num not in chapters:\n",
    "        continue\n",
    "    pred_sents.append(ps.text)\n",
    "    pv.append(ps.ref)\n",
    "\n",
    "alts = f\"({'|'.join(['f', 'x', 'fig', 'va', 'vp', 'ca'])})\"\n",
    "embeds_re = re.compile(fr\"\\\\{alts}.*?\\\\{alts}\\*\")\n",
    "\n",
    "# assume gold and pred have the exact same ScriptureRefs, as they should be based off the same original file\n",
    "tokenizer = WhitespaceSlashTokenizer() # handles 'word\\w' case\n",
    "# tokenizer = LatinWordTokenizer()\n",
    "vrefs = []\n",
    "gold_sent_toks = []\n",
    "pred_sent_toks = []\n",
    "num_markers = [] # number of USFM markers at each vref\n",
    "for ref, gs, ps in zip(all_vrefs, gold_sents, pred_sents):\n",
    "    # discard embeds, as of now they will always be at the end so they will only inflate the metrics\n",
    "    gs = embeds_re.sub(\"\", gs)\n",
    "    ps = embeds_re.sub(\"\", ps)\n",
    "\n",
    "    if gs.count(\"\\\\\") > 0:\n",
    "        vrefs.append(ref)\n",
    "        gold_sent_toks.append(list(tokenizer.tokenize(gs)))\n",
    "        pred_sent_toks.append(list(tokenizer.tokenize(ps)))\n",
    "        num_markers.append(gs.count(\"\\\\\"))\n",
    "\n",
    "'''\n",
    "Levenshtein distance\n",
    "raw score: num of insertions/substitutions/deletions/transpositions\n",
    "'''\n",
    "dists = [] # edit distance\n",
    "for vref, gs, ps, num_mark in zip(vrefs, gold_sent_toks, pred_sent_toks, num_markers):\n",
    "    dist = nltk.edit_distance(gs, ps, transpositions=True)\n",
    "    dists.append(dist)\n",
    "    # print(vref, dist, num_mark)\n",
    "    # print(gs)\n",
    "    # print(ps)\n",
    "\n",
    "dists_per_10_tokens = [d * 10 / len(gs) for d,gs in zip(dists, gold_sent_toks)]\n",
    "dists_per_marker = [d / n for d,n in zip(dists, num_markers)]\n",
    "\n",
    "'''\n",
    "Jaro similarity\n",
    "raw score:\n",
    "avg of:\n",
    "1. % matches in s1 (m / len(s1))\n",
    "2. % matches in s2 (m / len(s2))\n",
    "3. % matches not transposed ((m-t)/m), t = # \"half transposes\" / 2\n",
    "\n",
    "TODO: check symmetricality of Jaro similarity\n",
    "'''\n",
    "jaro_scores = []\n",
    "half_transposes = []\n",
    "for vref, gs, ps, num_mark in zip(vrefs, gold_sent_toks, pred_sent_toks, num_markers):\n",
    "    score, hts = jaro(gs, ps)\n",
    "    jaro_scores.append(score)\n",
    "    half_transposes.append(hts)\n",
    "    # print(score, half_transposes, num_mark, vref)\n",
    "    # print(gs)\n",
    "    # print(ps)\n",
    "\n",
    "ht_per_10_tokens = [t * 10 / len(g) for t,g in zip(half_transposes, gold_sent_toks)]\n",
    "ht_per_marker = [t / n for t,n in zip(half_transposes, num_markers)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of markers [2, 3, 3, 2, 2, 4, 2, 1, 1, 4, 3, 2, 4, 4, 1, 2, 2, 1, 5, 3, 1, 2, 2, 2, 2, 1, 4, 2, 5, 3, 3, 3, 3, 2, 1]\n",
      "sent lengths [19, 18, 19, 20, 22, 26, 17, 16, 16, 21, 20, 23, 23, 33, 30, 23, 17, 18, 30, 20, 13, 20, 18, 21, 21, 16, 26, 25, 36, 18, 16, 12, 38, 19, 18]\n",
      "avg markers 2.4857142857142858\n",
      "avg sent len 21.37142857142857\n",
      "\n",
      "\n",
      "Edit distance\n",
      "edit distance [18, 19, 21, 24, 20, 23, 16, 18, 17, 19, 21, 27, 30, 29, 28, 21, 23, 17, 30, 20, 17, 19, 20, 20, 21, 21, 30, 21, 33, 17, 15, 33, 33, 19, 25]\n",
      "dist per 10 tokens [9.473684210526315, 10.555555555555555, 11.052631578947368, 12.0, 9.090909090909092, 8.846153846153847, 9.411764705882353, 11.25, 10.625, 9.047619047619047, 10.5, 11.73913043478261, 13.043478260869565, 8.787878787878787, 9.333333333333334, 9.130434782608695, 13.529411764705882, 9.444444444444445, 10.0, 10.0, 13.076923076923077, 9.5, 11.11111111111111, 9.523809523809524, 10.0, 13.125, 11.538461538461538, 8.4, 9.166666666666666, 9.444444444444445, 9.375, 27.5, 8.68421052631579, 10.0, 13.88888888888889]\n",
      "dist per marker [9.0, 6.333333333333333, 7.0, 12.0, 10.0, 5.75, 8.0, 18.0, 17.0, 4.75, 7.0, 13.5, 7.5, 7.25, 28.0, 10.5, 11.5, 17.0, 6.0, 6.666666666666667, 17.0, 9.5, 10.0, 10.0, 10.5, 21.0, 7.5, 10.5, 6.6, 5.666666666666667, 5.0, 11.0, 11.0, 9.5, 25.0]\n",
      "\n",
      "\n",
      "avg dist       avg dist per 10 tokens       overall avg dist per 10 tokens       avg dist per marker       overall avg dist per marker\n",
      "22.428571428571427\t       10.891312732023941\t       10.494652406417112\t       10.929047619047621\t       9.022988505747126\n",
      "\n",
      "\n",
      "Jaro similarity\n",
      "jaro [0.4076367389060887, 0.36939571150097467, 0.3203083466241361, 0.36999999999999994, 0.4053030303030303, 0.3846153846153846, 0.3737745098039216, 0.37171052631578944, 0.32407407407407407, 0.4880952380952381, 0.4309523809523809, 0.39289387564282374, 0.29795854760791646, 0.35840548340548334, 0.42549019607843136, 0.3820450885668277, 0.4617698931424421, 0.4444444444444444, 0, 0, 0.37858220211161386, 0.46349206349206346, 0.3232323232323232, 0.4067460317460318, 0.4154761904761905, 0.47000000000000003, 0.34049773755656104, 0.48277777777777775, 0.43253968253968256, 0.43703703703703706, 0.34722222222222215, 0.44298245614035087, 0.44152046783625726, 0.4385964912280702, 0.37345679012345673]\n",
      "half transposes [0, 0, 2, 2, 0, 3, 0, 0, 4, 4, 0, 2, 2, 6, 0, 3, 5, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 3, 0, 2]\n",
      "transposes per 10 markers [0.0, 0.0, 1.0526315789473684, 1.0, 0.0, 1.1538461538461537, 0.0, 0.0, 2.5, 1.9047619047619047, 0.0, 0.8695652173913043, 0.8695652173913043, 1.8181818181818181, 0.0, 1.3043478260869565, 2.9411764705882355, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1111111111111112, 0.0, 0.9523809523809523, 0.0, 0.7692307692307693, 0.8, 0.0, 0.0, 1.25, 0.0, 0.7894736842105263, 0.0, 1.1111111111111112]\n",
      "transposes per marker [0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.75, 0.0, 0.0, 4.0, 1.0, 0.0, 1.0, 0.5, 1.5, 0.0, 1.5, 2.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 2.0]\n",
      "\n",
      "\n",
      "avg jaro       avg transposes       avg t's per 10 tokens       overall avg t's per 10 tokens       avg t's per marker       overall avg t's per marker\n",
      "0.37722951267425786\t       1.3714285714285714\t       0.6342109661497005\t       0.6417112299465241\t       0.6166666666666666\t       0.5517241379310345\n"
     ]
    }
   ],
   "source": [
    "print(\"number of markers\", num_markers)\n",
    "print(\"sent lengths\", [len(gs) for gs in gold_sent_toks])\n",
    "print(\"avg markers\", sum(num_markers) / len(vrefs))\n",
    "print(\"avg sent len\", sum([len(gs) for gs in gold_sent_toks]) / len(vrefs))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Edit distance\")\n",
    "print(\"edit distance\", dists)\n",
    "print(\"dist per 10 tokens\", dists_per_10_tokens)\n",
    "print(\"dist per marker\", dists_per_marker)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"avg dist \\\n",
    "      avg dist per 10 tokens \\\n",
    "      overall avg dist per 10 tokens \\\n",
    "      avg dist per marker \\\n",
    "      overall avg dist per marker\")\n",
    "print(f\"{sum(dists) / len(vrefs)}\\t \\\n",
    "      {sum(dists_per_10_tokens) / len(vrefs)}\\t \\\n",
    "      {sum(dists) * 10 / sum([len(gs) for gs in gold_sent_toks])}\\t \\\n",
    "      {sum(dists_per_marker) / len(vrefs)}\\t \\\n",
    "      {sum(dists) / sum(num_markers)}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Jaro similarity\")\n",
    "print(\"jaro\", jaro_scores)\n",
    "print(\"half transposes\", half_transposes)\n",
    "print(\"transposes per 10 markers\", ht_per_10_tokens)\n",
    "print(\"transposes per marker\", ht_per_marker)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"avg jaro \\\n",
    "      avg transposes \\\n",
    "      avg t's per 10 tokens \\\n",
    "      overall avg t's per 10 tokens \\\n",
    "      avg t's per marker \\\n",
    "      overall avg t's per marker\")\n",
    "print(f\"{sum(jaro_scores) / len(vrefs)}\\t \\\n",
    "      {sum(half_transposes) / len(vrefs)}\\t \\\n",
    "      {sum(ht_per_10_tokens) / len(vrefs)}\\t \\\n",
    "      {sum(half_transposes) * 10 / sum([len(g) for g in gold_sent_toks])}\\t \\\n",
    "      {sum(ht_per_marker) / len(vrefs)}\\t \\\n",
    "      {sum(half_transposes) / sum(num_markers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sentences(book_path: Path, project_path: Optional[Path] = None) -> List[str]:\n",
    "#     trg_settings = FileParatextProjectSettingsParser(book_path.parent if project_path is None else project_path).parse()\n",
    "#     trg_file_text = UsfmFileText(\n",
    "#         trg_settings.stylesheet,\n",
    "#         trg_settings.encoding,\n",
    "#         trg_settings.get_book_id(book_path.name),  # trg_settings.get_book_id(book_path.name)\n",
    "#         book_path,\n",
    "#         trg_settings.versification,\n",
    "#         include_markers=True,\n",
    "#         include_all_text=True,\n",
    "#         project=trg_settings.name,\n",
    "#     )\n",
    "#     tokenizer = UsfmTokenizer(trg_settings.stylesheet)\n",
    "\n",
    "#     trg_sents = []\n",
    "#     for sent in trg_file_text:\n",
    "#         if (len(sent.ref.path) > 0 and sent.ref.path[-1].name == \"rem\") or len(sent.text.strip()) == 0:\n",
    "#             continue\n",
    "#         trg_sents.append([\"\"])\n",
    "\n",
    "#         sent = sent.text.strip()\n",
    "#         usfm_toks = tokenizer.tokenize(sent)\n",
    "#         ignore_scope = None\n",
    "#         for j, tok in enumerate(usfm_toks):\n",
    "#             if ignore_scope is not None:\n",
    "#                 if tok.type == UsfmTokenType.END and tok.marker[:-1] == ignore_scope.marker:\n",
    "#                     ignore_scope = None\n",
    "#             elif tok.type == UsfmTokenType.NOTE or (tok.type == UsfmTokenType.CHARACTER and tok.marker == \"fig\"):\n",
    "#                 ignore_scope = tok\n",
    "#             elif tok.type == UsfmTokenType.TEXT:\n",
    "#                 trg_sents[-1][0] += tok.text\n",
    "\n",
    "#     return trg_sents\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
