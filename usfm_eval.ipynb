{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "from scipy.stats import pearsonr\n",
    "# import jaro\n",
    "\n",
    "from machine.annotations.range import Range\n",
    "from machine.corpora import FileParatextProjectSettingsParser, UsfmFileText, UsfmStylesheet\n",
    "from machine.tokenization import WhitespaceTokenizer, LatinWordTokenizer\n",
    "\n",
    "class WhitespaceSlashTokenizer(WhitespaceTokenizer):\n",
    "    def _is_whitespace(self, c: str) -> bool:\n",
    "        return super()._is_whitespace(c) or c == \"\\\\\" or c == \"*\"\n",
    "\n",
    "class LatinMarkerWordTokeinzer(LatinWordTokenizer):\n",
    "    def _process_character(self, data, data_range, ctxt):\n",
    "        if data[ctxt.index] == \"\\\\\":\n",
    "            space_idx = data.index(\" \", ctxt.index+1) if \" \" in data[ctxt.index+1:] else data_range.end\n",
    "            slash_idx = data.index(\"\\\\\", ctxt.index+1) if \"\\\\\" in data[ctxt.index+1:] else data_range.end\n",
    "            star_idx = data.index(\"*\", ctxt.index+1) if \"*\" in data[ctxt.index+1:] else data_range.end\n",
    "            marker_end = min(space_idx, slash_idx, star_idx)\n",
    "            if marker_end == star_idx: # asterisk is part of marker\n",
    "                marker_end += 1\n",
    "\n",
    "            token_ranges = (Range.create(ctxt.index, marker_end), None)\n",
    "            ctxt.index = marker_end\n",
    "            return token_ranges\n",
    "\n",
    "        return super()._process_character(data, data_range, ctxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Code from https://github.com/richmilne/JaroWinkler/blob/master/jaro/jaro.py'''\n",
    "\n",
    "def jaro(s1, s2):\n",
    "    # s1 is always the shorter string\n",
    "    if len(s2) < len(s1):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    if len(s1) == 0:\n",
    "        print(\"empty sequence\")\n",
    "        print(s1)\n",
    "        print(s2)\n",
    "        return 0, 0\n",
    "\n",
    "    search_range = max((len(s2) // 2) - 1, 0)\n",
    "    matched1 = [0] * len(s1)\n",
    "    matched2 = [0] * len(s2)\n",
    "    num_matches = 0\n",
    "\n",
    "    for i, char in enumerate(s1):\n",
    "        for j in range(max(i - search_range, 0), min(i + search_range, len(s2) - 1) + 1):\n",
    "            if not matched2[j] and char == s2[j]:\n",
    "                matched1[i] = matched2[j] = 1\n",
    "                num_matches += 1\n",
    "                break\n",
    "    \n",
    "    if num_matches == 0:\n",
    "        print(\"no matches\")\n",
    "        print(s1)\n",
    "        print(s2)\n",
    "        return 0, 0\n",
    "\n",
    "    # number of matched tokens in s1 such that if it is the ith matched token, the the ith matched token in s2 (in linear order) is not what it was matched with\n",
    "    # this number divided by 2 is the number of transpositions\n",
    "    half_transposes = 0\n",
    "    j = 0\n",
    "    for i, matched in enumerate(matched1):\n",
    "        if not matched:\n",
    "            continue\n",
    "        while not matched2[j]:\n",
    "            j += 1\n",
    "        if s1[i] != s2[j]:\n",
    "            half_transposes += 1\n",
    "        j += 1\n",
    "\n",
    "    dist = (\n",
    "        num_matches / len(s1)\n",
    "        + num_matches / len(s2)\n",
    "        + (num_matches - half_transposes // 2) / num_matches\n",
    "        ) / 3\n",
    "    return dist, half_transposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Levenshtein distance\n",
    "raw score: num of insertions/substitutions/deletions/transpositions\n",
    "'''\n",
    "def levenshtein_metrics(gs_toks, ps_toks, num_markers):\n",
    "    dists = [] # edit distance\n",
    "    for gs, ps in zip(gs_toks, ps_toks):\n",
    "        dist = nltk.edit_distance(gs, ps, transpositions=True)\n",
    "        dists.append(dist)\n",
    "\n",
    "    dists_per_10_tokens = [d * 10 / len(gs) for d,gs in zip(dists, gs_toks)]\n",
    "    dists_per_marker = [d / n for d,n in zip(dists, num_markers)]\n",
    "    return dists, dists_per_10_tokens, dists_per_marker\n",
    "\n",
    "'''\n",
    "Jaro similarity\n",
    "raw score:\n",
    "avg of:\n",
    "1. % matches in s1 (m / len(s1))\n",
    "2. % matches in s2 (m / len(s2))\n",
    "3. % matches not transposed ((m-t)/m), t = # \"half transposes\" / 2\n",
    "\n",
    "TODO: check symmetricality of Jaro similarity\n",
    "'''\n",
    "def jaro_metrics(gs_toks, ps_toks, num_markers):\n",
    "    jaro_scores = []\n",
    "    half_transposes = []\n",
    "    for gs, ps in zip(gs_toks, ps_toks):\n",
    "        score, hts = jaro(gs, ps)\n",
    "        jaro_scores.append(score)\n",
    "        half_transposes.append(hts)\n",
    "\n",
    "    ht_per_tok = [t * 10 / len(g) for t,g in zip(half_transposes, gs_toks)]\n",
    "    ht_per_mark = [t / n for t,n in zip(half_transposes, num_markers)]\n",
    "    return jaro_scores, half_transposes, ht_per_tok, ht_per_mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gold sentences: constructed \"goal\" files, ideally based on source project but typically based on target project\n",
    "# # predicted sentences: translated output, based on source project\n",
    "# project_path = Path(\"test_S/Paratext/projects/aArpBT_2024_09_19\")\n",
    "# book = \"MAT\"\n",
    "# chapters = {2,3,4}\n",
    "# gold_file_path = Path(\"zzz_USFM_eval/aa_gold_standard/tpi_aps_41MATaArp_2_4.SFM\")\n",
    "# pred_file_path = Path(\"zzz_USFM_eval/tpi_aps/41MAT_hmm.SFM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings = FileParatextProjectSettingsParser(project_path).parse()\n",
    "# gold_file_text = UsfmFileText(\n",
    "#     settings.stylesheet,\n",
    "#     settings.encoding,\n",
    "#     book,\n",
    "#     gold_file_path,\n",
    "#     settings.versification,\n",
    "#     include_markers=True,\n",
    "#     include_all_text=True,\n",
    "#     project=settings.name,\n",
    "# )\n",
    "# pred_file_text = UsfmFileText(\n",
    "#     settings.stylesheet,\n",
    "#     settings.encoding,\n",
    "#     book,\n",
    "#     pred_file_path,\n",
    "#     settings.versification,\n",
    "#     include_markers=True,\n",
    "#     include_all_text=True,\n",
    "#     project=settings.name,\n",
    "# )\n",
    "\n",
    "# '''Preprocess'''\n",
    "# # have to iterate over individually at first because gold standard file only contains the specific chapters\n",
    "# ignore = [\"r\", \"rem\"]\n",
    "# all_vrefs = []\n",
    "# gold_sents = []\n",
    "# for gs in gold_file_text:\n",
    "#     if (len(gs.ref.path) > 0 and gs.ref.path[-1].name in ignore) or gs.ref.chapter_num not in chapters:\n",
    "#         continue\n",
    "#     all_vrefs.append(gs.ref)\n",
    "#     gold_sents.append(gs.text)\n",
    "# pred_sents = []\n",
    "# pv = []\n",
    "# for ps in pred_file_text:\n",
    "#     if (len(ps.ref.path) > 0 and ps.ref.path[-1].name in ignore) or ps.ref.chapter_num not in chapters:\n",
    "#         continue\n",
    "#     pred_sents.append(ps.text)\n",
    "#     pv.append(ps.ref)\n",
    "\n",
    "# alts = f\"({'|'.join(['f', 'x', 'fig', 'va', 'vp', 'ca'])})\"\n",
    "# embeds_re = re.compile(fr\"\\\\{alts}.*?\\\\{alts}\\*\")\n",
    "\n",
    "# # assume gold and pred have the exact same ScriptureRefs, as they should be based off the same original file\n",
    "# tokenizer = WhitespaceSlashTokenizer() # handles 'word\\w' case\n",
    "# # tokenizer = LatinWordTokenizer()\n",
    "# vrefs = []\n",
    "# gold_sent_toks = []\n",
    "# pred_sent_toks = []\n",
    "# num_markers = [] # number of USFM markers at each vref\n",
    "# for ref, gs, ps in zip(all_vrefs, gold_sents, pred_sents):\n",
    "#     # discard embeds, as of now they will always be at the end so they will only inflate the metrics\n",
    "#     gs = embeds_re.sub(\"\", gs)\n",
    "#     ps = embeds_re.sub(\"\", ps)\n",
    "\n",
    "#     if gs.count(\"\\\\\") > 0:\n",
    "#         vrefs.append(ref)\n",
    "#         gold_sent_toks.append(list(tokenizer.tokenize(gs)))\n",
    "#         pred_sent_toks.append(list(tokenizer.tokenize(ps)))\n",
    "#         num_markers.append(gs.count(\"\\\\\"))\n",
    "\n",
    "# '''\n",
    "# Levenshtein distance\n",
    "# raw score: num of insertions/substitutions/deletions/transpositions\n",
    "# '''\n",
    "# dists = [] # edit distance\n",
    "# for vref, gs, ps, num_mark in zip(vrefs, gold_sent_toks, pred_sent_toks, num_markers):\n",
    "#     dist = nltk.edit_distance(gs, ps, transpositions=True)\n",
    "#     dists.append(dist)\n",
    "#     # print(vref, dist, num_mark)\n",
    "#     # print(gs)\n",
    "#     # print(ps)\n",
    "\n",
    "# dists_per_10_tokens = [d * 10 / len(gs) for d,gs in zip(dists, gold_sent_toks)]\n",
    "# dists_per_marker = [d / n for d,n in zip(dists, num_markers)]\n",
    "\n",
    "# '''\n",
    "# Jaro similarity\n",
    "# raw score:\n",
    "# avg of:\n",
    "# 1. % matches in s1 (m / len(s1))\n",
    "# 2. % matches in s2 (m / len(s2))\n",
    "# 3. % matches not transposed ((m-t)/m), t = # \"half transposes\" / 2\n",
    "\n",
    "# TODO: check symmetricality of Jaro similarity\n",
    "# '''\n",
    "# jaro_scores = []\n",
    "# half_transposes = []\n",
    "# for vref, gs, ps, num_mark in zip(vrefs, gold_sent_toks, pred_sent_toks, num_markers):\n",
    "#     score, hts = jaro(gs, ps)\n",
    "#     jaro_scores.append(score)\n",
    "#     half_transposes.append(hts)\n",
    "#     # print(score, half_transposes, num_mark, vref)\n",
    "#     # print(gs)\n",
    "#     # print(ps)\n",
    "\n",
    "# ht_per_10_tokens = [t * 10 / len(g) for t,g in zip(half_transposes, gold_sent_toks)]\n",
    "# ht_per_marker = [t / n for t,n in zip(half_transposes, num_markers)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Evaluation\n",
    "simplified code for constructed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prefix = \"23ISA_1_spa\" # \"41MAT_1_eng\"\n",
    "n = 5\n",
    "# transpositions per verse, transpositions per marker\n",
    "# [.92, .92, 1.69, 3.08, 15.62] [.48, .48, .88, 1.60, 8.12]\n",
    "# [.27, 11.17, 1.73, 5.67, 12.67] [.08, 3.28, .51, 1.67, 3.73]\n",
    "# human_eval_scores = [.27, 11.17, 1.73, 5.67, 12.67][:n]\n",
    "human_eval_scores = [.08, 3.28, .51, 1.67, 3.73][:n]\n",
    "\n",
    "# custom tokenizers handle markers\n",
    "# tokenizer = WhitespaceSlashTokenizer()\n",
    "# tokenizer = LatinMarkerWordTokeinzer()\n",
    "tokenizer = None\n",
    "\n",
    "gold_file_path = Path(f\"zzz_USFM_eval_eval/{test_prefix}/{test_prefix}_gold.SFM\")\n",
    "gold_file_text = UsfmFileText(\"usfm.sty\", \"utf-8-sig\", test_prefix[2:5], gold_file_path, include_markers=True, include_all_text=True)\n",
    "\n",
    "pred_file_paths = [Path(f\"zzz_USFM_eval_eval/{test_prefix}/{test_prefix}_pred_{i+1}.SFM\") for i in range(n)]\n",
    "\n",
    "sent_idxs = []\n",
    "vrefs = []\n",
    "markers = []\n",
    "for i, gs in enumerate(gold_file_text):\n",
    "    if gs.text.count(\"\\\\\") > 0:\n",
    "        sent_idxs.append(i)\n",
    "        vrefs.append(gs.ref)\n",
    "        markers.append(re.findall(r\"\\\\[^\\s\\\\\\*]*\\*?\", gs.text)) # TODO: make sure this works for each gold file, will have to change for the other tokenizers\n",
    "\n",
    "        if tokenizer and not isinstance(tokenizer, LatinMarkerWordTokeinzer):\n",
    "            for j in range(len(markers[-1])):\n",
    "                markers[-1][j] = markers[-1][j].strip(\"\\\\*\")\n",
    "num_markers = [len(m) for m in markers]\n",
    "\n",
    "gold_sent_toks = []\n",
    "for i, gs in enumerate(gold_file_text):\n",
    "    if i in sent_idxs:\n",
    "        if tokenizer:\n",
    "            gold_sent_toks.append(list(tokenizer.tokenize(gs.text)))\n",
    "        else:\n",
    "            gold_sent_toks.append(gs.text)\n",
    "\n",
    "# for sent in gold_sent_toks:\n",
    "#     print(\" \".join(sent))\n",
    "\n",
    "'''get scores'''\n",
    "edit_dists, edit_dists_per_10_tokens, edit_dists_per_marker = [], [], []\n",
    "jaro_scores, half_transposes, hts_per_10_tokens, hts_per_marker = [], [], [], []\n",
    "for pred_file_path in pred_file_paths:\n",
    "    pred_file_text = UsfmFileText(\"usfm.sty\", \"utf-8-sig\", test_prefix[2:5], pred_file_path, include_markers=True, include_all_text=True)\n",
    "    pred_sent_toks = []\n",
    "    for i, ps in enumerate(pred_file_text):\n",
    "        if i in sent_idxs:\n",
    "            if tokenizer:\n",
    "                pred_sent_toks.append(list(tokenizer.tokenize(ps.text)))\n",
    "            else:\n",
    "                pred_sent_toks.append(ps.text)\n",
    "\n",
    "    # TODO: this assumes that the markers will come in order, need to do something like find first instance of marker and cut from string, continue to search whole string\n",
    "    # insert any missing markers at the end\n",
    "    # if the prediction file leaves paragraphs at the end of a verse empty, they will not be returned by the parser\n",
    "    for i in range(len(markers)):\n",
    "        marker_idx = 0\n",
    "        if tokenizer:\n",
    "            for tok in pred_sent_toks[i]:\n",
    "                if marker_idx >= len(markers[i]):\n",
    "                    break\n",
    "                marker_idx += tok == markers[i][marker_idx]\n",
    "        else:\n",
    "            pos = 0\n",
    "            while pos < len(pred_sent_toks[i]):\n",
    "                if marker_idx >= len(markers[i]):\n",
    "                    break\n",
    "                if markers[i][marker_idx] in pred_sent_toks[i][pos:]:\n",
    "                    pos = pred_sent_toks[i].index(markers[i][marker_idx], pos) + len(markers[i][marker_idx])\n",
    "                    marker_idx += 1\n",
    "                else:\n",
    "                    break\n",
    "        for j in range(marker_idx, len(markers[i])):\n",
    "            if tokenizer:\n",
    "                pred_sent_toks[i].append(markers[i][j])\n",
    "            else:\n",
    "                pred_sent_toks[i] += \" \" + markers[i][j]\n",
    "    \n",
    "    # for sent in pred_sent_toks:\n",
    "    #     print(\" \".join(sent))\n",
    "\n",
    "    dists, dists_per_10_tokens, dists_per_marker = levenshtein_metrics(gold_sent_toks, pred_sent_toks, num_markers)\n",
    "    edit_dists.append(dists)\n",
    "    edit_dists_per_10_tokens.append(dists_per_10_tokens)\n",
    "    edit_dists_per_marker.append(dists_per_marker)\n",
    "\n",
    "    scores, hts, ht_per_tok, ht_per_mark = jaro_metrics(gold_sent_toks, pred_sent_toks, num_markers)\n",
    "    jaro_scores.append(scores)\n",
    "    half_transposes.append(hts)\n",
    "    hts_per_10_tokens.append(ht_per_tok)\n",
    "    hts_per_marker.append(ht_per_mark)\n",
    "\n",
    "'''calculate summary stats'''\n",
    "avg_dist = [sum(ed) / len(vrefs) for ed in edit_dists]\n",
    "avg_dist_per_10_tokens = [sum(edpt) / len(vrefs) for edpt in edit_dists_per_10_tokens]\n",
    "overall_avg_dist_per_10_tokens = [sum(ed) * 10 / sum([len(gs) for gs in gold_sent_toks]) for ed in edit_dists]\n",
    "avg_dist_per_marker = [sum(edpm) / len(vrefs) for edpm in edit_dists_per_marker]\n",
    "overall_avg_dist_per_marker = [sum(ed) / sum(num_markers) for ed in edit_dists]\n",
    "\n",
    "avg_jaro = [sum(js) / len(vrefs) for js in jaro_scores]\n",
    "avg_transposes = [sum(hts) / len(vrefs) for hts in half_transposes]\n",
    "avg_ts_per_10_tokens = [sum(htpt) / len(vrefs) for htpt in hts_per_10_tokens]\n",
    "overall_avg_ts_per_10_tokens = [sum(hts) * 10 / sum([len(g) for g in gold_sent_toks]) for hts in half_transposes]\n",
    "avg_ts_per_marker = [sum(htpm) / len(vrefs) for htpm in hts_per_marker]\n",
    "overall_avg_ts_per_marker = [sum(hts) / sum(num_markers) for hts in half_transposes]\n",
    "\n",
    "'''calculate Pearson's correlation coefficient'''\n",
    "res = pearsonr(human_eval_scores, avg_dist)\n",
    "avg_dist_pearson = res.statistic\n",
    "avg_dist_p = res.pvalue\n",
    "\n",
    "res = pearsonr(human_eval_scores, avg_dist_per_10_tokens)\n",
    "avg_dist_per_10_tokens_pearson = res.statistic\n",
    "avg_dist_per_10_tokens_p = res.pvalue\n",
    "\n",
    "res = pearsonr(human_eval_scores, overall_avg_dist_per_10_tokens)\n",
    "overall_avg_dist_per_10_tokens_pearson = res.statistic\n",
    "overall_avg_dist_per_10_tokens_p = res.pvalue\n",
    "\n",
    "res = pearsonr(human_eval_scores, avg_dist_per_marker)\n",
    "avg_dist_per_marker_pearson = res.statistic\n",
    "avg_dist_per_marker_p = res.pvalue\n",
    "\n",
    "res = pearsonr(human_eval_scores, overall_avg_dist_per_marker)\n",
    "overall_avg_dist_per_marker_pearson = res.statistic\n",
    "overall_avg_dist_per_marker_p = res.pvalue\n",
    "\n",
    "res = pearsonr(human_eval_scores, avg_jaro)\n",
    "avg_jaro_pearson = res.statistic\n",
    "avg_jaro_p = res.pvalue\n",
    "\n",
    "res = pearsonr(human_eval_scores, avg_transposes)\n",
    "avg_transposes_pearson = res.statistic\n",
    "avg_transposes_p = res.pvalue\n",
    "\n",
    "res = pearsonr(human_eval_scores, avg_ts_per_10_tokens)\n",
    "avg_ts_per_10_tokens_pearson = res.statistic\n",
    "avg_ts_per_10_tokens_p = res.pvalue\n",
    "\n",
    "res = pearsonr(human_eval_scores, overall_avg_ts_per_10_tokens)\n",
    "overall_avg_ts_per_10_tokens_pearson = res.statistic\n",
    "overall_avg_ts_per_10_tokens_p = res.pvalue\n",
    "\n",
    "res = pearsonr(human_eval_scores, avg_ts_per_marker)\n",
    "avg_ts_per_marker_pearson = res.statistic\n",
    "avg_ts_per_marker_p = res.pvalue\n",
    "\n",
    "res = pearsonr(human_eval_scores, overall_avg_ts_per_marker)\n",
    "overall_avg_ts_per_marker_pearson = res.statistic\n",
    "overall_avg_ts_per_marker_p = res.pvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of markers [5, 3, 8, 3, 4, 5, 3, 4, 4, 6, 1, 4, 2, 4, 2, 4, 7, 1, 4, 4, 1, 5, 5, 2, 3, 1, 1, 2, 1, 3]\n",
      "sent lengths [139, 139, 213, 159, 195, 235, 168, 132, 135, 211, 90, 206, 114, 181, 87, 165, 242, 73, 112, 176, 82, 208, 152, 121, 178, 94, 81, 110, 84, 136]\n",
      "avg markers 3.4\n",
      "avg sent len 147.26666666666668\n",
      "all markers [['\\\\q1', '\\\\nd', '\\\\nd*', '\\\\q1', '\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1', '\\\\nd', '\\\\nd*', '\\\\q1', '\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\nd', '\\\\nd*', '\\\\q1', '\\\\q1'], ['\\\\nd', '\\\\nd*', '\\\\q1', '\\\\q1'], ['\\\\nd', '\\\\nd*', '\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\q1', '\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\q1', '\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\nd', '\\\\nd*', '\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\nd', '\\\\nd*'], ['\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\nd', '\\\\nd*', '\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\q1', '\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\q1'], ['\\\\q1'], ['\\\\q1'], ['\\\\q1', '\\\\q1'], ['\\\\q1'], ['\\\\q1', '\\\\q1', '\\\\q1']]\n",
      "\n",
      "\n",
      "Edit distance\n",
      "edit distance\n",
      "[8, 0, 8, 0, 0, 0, 0, 8, 8, 8, 0, 0, 0, 0, 0, 0, 8, 0, 8, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0]\n",
      "[24, 0, 24, 0, 0, 0, 0, 24, 25, 32, 0, 0, 0, 0, 0, 0, 36, 0, 16, 0, 0, 0, 28, 0, 0, 0, 0, 0, 0, 0]\n",
      "[11, 0, 15, 0, 0, 0, 0, 10, 16, 6, 0, 0, 0, 0, 0, 0, 20, 0, 10, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 8, 12, 0, 8, 8, 0, 8, 12, 8, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 16, 8, 17, 24, 8, 24, 8, 8, 16, 8, 8, 16, 8, 16]\n",
      "dist per 10 tokens\n",
      "[0.5755395683453237, 0.0, 0.3755868544600939, 0.0, 0.0, 0.0, 0.0, 0.6060606060606061, 0.5925925925925926, 0.3791469194312796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3305785123966942, 0.0, 0.7142857142857143, 0.0, 0.0, 0.0, 0.5263157894736842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1.7266187050359711, 0.0, 1.1267605633802817, 0.0, 0.0, 0.0, 0.0, 1.8181818181818181, 1.8518518518518519, 1.5165876777251184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.487603305785124, 0.0, 1.4285714285714286, 0.0, 0.0, 0.0, 1.8421052631578947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.7913669064748201, 0.0, 0.704225352112676, 0.0, 0.0, 0.0, 0.0, 0.7575757575757576, 1.1851851851851851, 0.2843601895734597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8264462809917356, 0.0, 0.8928571428571429, 0.0, 0.0, 0.0, 1.3157894736842106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.5755395683453237, 0.5633802816901409, 0.0, 0.41025641025641024, 0.3404255319148936, 0.0, 0.6060606060606061, 0.8888888888888888, 0.3791469194312796, 0.0, 0.3883495145631068, 0.7017543859649122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.9393939393939394, 0.6611570247933884, 1.095890410958904, 1.5178571428571428, 1.3636363636363635, 0.975609756097561, 1.1538461538461537, 0.5263157894736842, 0.6611570247933884, 0.898876404494382, 0.851063829787234, 0.9876543209876543, 1.4545454545454546, 0.9523809523809523, 1.1764705882352942]\n",
      "dist per marker\n",
      "[1.6, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1428571428571428, 0.0, 2.0, 0.0, 0.0, 0.0, 1.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[4.8, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.25, 5.333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.142857142857143, 0.0, 4.0, 0.0, 0.0, 0.0, 5.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[2.2, 0.0, 1.875, 0.0, 0.0, 0.0, 0.0, 2.5, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.857142857142857, 0.0, 2.5, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 2.6666666666666665, 1.5, 0.0, 2.0, 1.6, 0.0, 2.0, 3.0, 1.3333333333333333, 0.0, 2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.2857142857142856, 8.0, 4.25, 6.0, 8.0, 4.8, 1.6, 4.0, 5.333333333333333, 8.0, 8.0, 8.0, 8.0, 5.333333333333333]\n",
      "\n",
      "\n",
      "Jaro similarity\n",
      "jaro\n",
      "[0.9904076738609113, 1.0, 0.9937402190923317, 1.0, 1.0, 1.0, 1.0, 0.98989898989899, 0.9901234567901235, 0.9936808846761455, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9944903581267218, 1.0, 0.9880952380952381, 1.0, 1.0, 1.0, 0.9912280701754387, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.8551173466988714, 1.0, 0.9269007711426932, 1.0, 1.0, 1.0, 1.0, 0.824986124986125, 0.8587542087542087, 0.821075979507614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8183780613254151, 1.0, 0.9523809523809524, 1.0, 1.0, 1.0, 0.8197565139727695, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.8825111339499828, 1.0, 0.9827856025039123, 1.0, 1.0, 1.0, 1.0, 0.9722222222222222, 0.9407407407407407, 0.995260663507109, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9587672736231495, 1.0, 0.9732142857142857, 1.0, 1.0, 1.0, 0.938821412505623, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[1.0, 0.9400479616306955, 0.8561404267901315, 1.0, 0.8717948717948718, 0.9148936170212766, 1.0, 0.8813131313131314, 0.8965805133670841, 0.9462875197472354, 1.0, 0.9190938511326862, 0.9649122807017544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8541339319117096, 0.9187327823691461, 0.8784487748408258, 0.8650875639512003, 0.8679031696273075, 0.9227642276422765, 0.8576674134926563, 0.8837719298245613, 0.9008264462809917, 0.8838951310861424, 0.8879895158803577, 0.934156378600823, 0.9181818181818181, 0.9285714285714285, 0.8897058823529411]\n",
      "half transposes\n",
      "[9, 0, 9, 0, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 0, 9, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0]\n",
      "[92, 0, 79, 0, 0, 0, 0, 115, 85, 192, 0, 0, 0, 0, 0, 0, 222, 0, 32, 0, 0, 0, 129, 0, 0, 0, 0, 0, 0, 0]\n",
      "[96, 0, 22, 0, 0, 0, 0, 23, 48, 6, 0, 0, 0, 0, 0, 0, 53, 0, 19, 0, 0, 0, 49, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 51, 177, 0, 150, 121, 0, 94, 76, 68, 0, 100, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 130, 119, 44, 74, 130, 38, 169, 107, 72, 125, 55, 33, 54, 36, 90]\n",
      "transposes per 10 tokens\n",
      "[0.6474820143884892, 0.0, 0.4225352112676056, 0.0, 0.0, 0.0, 0.0, 0.6818181818181818, 0.6666666666666666, 0.4265402843601896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.371900826446281, 0.0, 0.8035714285714286, 0.0, 0.0, 0.0, 0.5921052631578947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[6.618705035971223, 0.0, 3.708920187793427, 0.0, 0.0, 0.0, 0.0, 8.712121212121213, 6.296296296296297, 9.09952606635071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.173553719008265, 0.0, 2.857142857142857, 0.0, 0.0, 0.0, 8.486842105263158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[6.906474820143885, 0.0, 1.0328638497652582, 0.0, 0.0, 0.0, 0.0, 1.7424242424242424, 3.5555555555555554, 0.2843601895734597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.190082644628099, 0.0, 1.6964285714285714, 0.0, 0.0, 0.0, 3.223684210526316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 3.6690647482014387, 8.309859154929578, 0.0, 7.6923076923076925, 5.148936170212766, 0.0, 7.121212121212121, 5.62962962962963, 3.2227488151658767, 0.0, 4.854368932038835, 2.1052631578947367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.878787878787879, 4.917355371900826, 6.027397260273973, 6.607142857142857, 7.386363636363637, 4.634146341463414, 8.125, 7.0394736842105265, 5.950413223140496, 7.022471910112359, 5.851063829787234, 4.074074074074074, 4.909090909090909, 4.285714285714286, 6.617647058823529]\n",
      "transposes per marker\n",
      "[1.8, 0.0, 1.125, 0.0, 0.0, 0.0, 0.0, 2.25, 2.25, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.2857142857142858, 0.0, 2.25, 0.0, 0.0, 0.0, 1.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[18.4, 0.0, 9.875, 0.0, 0.0, 0.0, 0.0, 28.75, 21.25, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.714285714285715, 0.0, 8.0, 0.0, 0.0, 0.0, 25.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[19.2, 0.0, 2.75, 0.0, 0.0, 0.0, 0.0, 5.75, 12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.571428571428571, 0.0, 4.75, 0.0, 0.0, 0.0, 9.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 17.0, 22.125, 0.0, 37.5, 24.2, 0.0, 23.5, 19.0, 11.333333333333334, 0.0, 25.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.5, 17.0, 44.0, 18.5, 32.5, 38.0, 33.8, 21.4, 36.0, 41.666666666666664, 55.0, 33.0, 27.0, 36.0, 30.0]\n",
      "\n",
      "\n",
      "avg dist       avg dist per 10 tokens       overall avg dist per 10 tokens       avg dist per marker       overall avg dist per marker\n",
      "2.1333333333333333\t         0.1366702185681996\t         0.1448619284744228\t         0.4225396825396825\t         0.6274509803921569\n",
      "6.966666666666667\t         0.42660935378964965\t         0.473064735174287\t         1.3375396825396826\t         2.049019607843137\n",
      "3.6\t         0.22526020961516624\t         0.24445450430058852\t         0.6977380952380953\t         1.0588235294117647\n",
      "2.6666666666666665\t         0.16179340357051875\t         0.1810774105930285\t         0.67\t         0.7843137254901961\n",
      "7.233333333333333\t         0.5405285052093833\t         0.49117247623358984\t         2.9867460317460317\t         2.127450980392157\n",
      "\n",
      "\n",
      "avg jaro       avg transposes       avg t's per 10 tokens       overall avg t's per 10 tokens       avg t's per marker       overall avg t's per marker\n",
      "0.9977221630238632\t         2.4\t         0.15375399588922456\t         0.16296966953372566\t         0.4753571428571429\t         0.7058823529411765\n",
      "0.962578331958955\t         31.533333333333335\t         1.8317702493315717\t         2.141240380262562\t         5.859642857142858\t         9.27450980392157\n",
      "0.9881441111589008\t         10.533333333333333\t         0.6877291361348462\t         0.7152557718424627\t         2.094047619047619\t         3.0980392156862746\n",
      "0.9730354724499624\t         28.7\t         1.5917796807197562\t         1.9488456315074694\t         6.3886111111111115\t         8.441176470588236\n",
      "0.9463945464871394\t         42.53333333333333\t         3.044204744029534\t         2.888184698958805\t         16.54555555555556\t         12.509803921568627\n",
      "\n",
      "\n",
      "summary stats\n",
      "2.1333333333333333\t         0.1366702185681996\t         0.1448619284744228\t         0.4225396825396825\t         0.6274509803921569\t         0.9977221630238632\t         2.4\t         0.15375399588922456\t         0.16296966953372566\t         0.4753571428571429\t         0.7058823529411765\n",
      "6.966666666666667\t         0.42660935378964965\t         0.473064735174287\t         1.3375396825396826\t         2.049019607843137\t         0.962578331958955\t         31.533333333333335\t         1.8317702493315717\t         2.141240380262562\t         5.859642857142858\t         9.27450980392157\n",
      "3.6\t         0.22526020961516624\t         0.24445450430058852\t         0.6977380952380953\t         1.0588235294117647\t         0.9881441111589008\t         10.533333333333333\t         0.6877291361348462\t         0.7152557718424627\t         2.094047619047619\t         3.0980392156862746\n",
      "2.6666666666666665\t         0.16179340357051875\t         0.1810774105930285\t         0.67\t         0.7843137254901961\t         0.9730354724499624\t         28.7\t         1.5917796807197562\t         1.9488456315074694\t         6.3886111111111115\t         8.441176470588236\n",
      "7.233333333333333\t         0.5405285052093833\t         0.49117247623358984\t         2.9867460317460317\t         2.127450980392157\t         0.9463945464871394\t         42.53333333333333\t         3.044204744029534\t         2.888184698958805\t         16.54555555555556\t         12.509803921568627\n",
      "Pearson correlation coefficients and p-values\n",
      "0.9177788750933685\t       0.9116656285681128\t       0.9177788750933686\t       0.8421256877699411\t       0.9177788750933684\t       -0.9765428239409947\t       0.9532017476032513\t       0.9442892966920708\t       0.953201747603251\t       0.8502058929857553\t       0.9532017476032513\n",
      "0.02794981797603041\t       0.031094866938751266\t       0.02794981797603041\t       0.0734918999539393\t       0.027949817976030526\t       0.004297475694889999\t       0.012067185240833457\t       0.015652327905240217\t       0.012067185240833542\t       0.06800938693508814\t       0.012067185240833457\n"
     ]
    }
   ],
   "source": [
    "print(\"number of markers\", num_markers)\n",
    "print(\"sent lengths\", [len(gs) for gs in gold_sent_toks])\n",
    "print(\"avg markers\", sum(num_markers) / len(vrefs))\n",
    "print(\"avg sent len\", sum([len(gs) for gs in gold_sent_toks]) / len(vrefs))\n",
    "print(\"all markers\", markers)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Edit distance\")\n",
    "print(\"edit distance\")\n",
    "for ed in edit_dists:\n",
    "    print(ed)\n",
    "print(\"dist per 10 tokens\")\n",
    "for edpt in edit_dists_per_10_tokens:\n",
    "    print(edpt)\n",
    "print(\"dist per marker\")\n",
    "for edpm in edit_dists_per_marker:\n",
    "    print(edpm)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Jaro similarity\")\n",
    "print(\"jaro\")\n",
    "for js in jaro_scores:\n",
    "    print(js)\n",
    "print(\"half transposes\")\n",
    "for hts in half_transposes:\n",
    "    print(hts)\n",
    "print(\"transposes per 10 tokens\")\n",
    "for htpt in hts_per_10_tokens:\n",
    "    print(htpt)\n",
    "print(\"transposes per marker\")\n",
    "for htpm in hts_per_marker:\n",
    "    print(htpm)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"avg dist \\\n",
    "      avg dist per 10 tokens \\\n",
    "      overall avg dist per 10 tokens \\\n",
    "      avg dist per marker \\\n",
    "      overall avg dist per marker\")\n",
    "for i in range(len(pred_file_paths)):\n",
    "    print(f\"{avg_dist[i]}\\t \\\n",
    "        {avg_dist_per_10_tokens[i]}\\t \\\n",
    "        {overall_avg_dist_per_10_tokens[i]}\\t \\\n",
    "        {avg_dist_per_marker[i]}\\t \\\n",
    "        {overall_avg_dist_per_marker[i]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"avg jaro \\\n",
    "      avg transposes \\\n",
    "      avg t's per 10 tokens \\\n",
    "      overall avg t's per 10 tokens \\\n",
    "      avg t's per marker \\\n",
    "      overall avg t's per marker\")\n",
    "for i in range(len(pred_file_paths)):\n",
    "    print(f\"{avg_jaro[i]}\\t \\\n",
    "        {avg_transposes[i]}\\t \\\n",
    "        {avg_ts_per_10_tokens[i]}\\t \\\n",
    "        {overall_avg_ts_per_10_tokens[i]}\\t \\\n",
    "        {avg_ts_per_marker[i]}\\t \\\n",
    "        {overall_avg_ts_per_marker[i]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"summary stats\")\n",
    "for i in range(len(pred_file_paths)):\n",
    "    print(f\"{avg_dist[i]}\\t \\\n",
    "        {avg_dist_per_10_tokens[i]}\\t \\\n",
    "        {overall_avg_dist_per_10_tokens[i]}\\t \\\n",
    "        {avg_dist_per_marker[i]}\\t \\\n",
    "        {overall_avg_dist_per_marker[i]}\\t \\\n",
    "        {avg_jaro[i]}\\t \\\n",
    "        {avg_transposes[i]}\\t \\\n",
    "        {avg_ts_per_10_tokens[i]}\\t \\\n",
    "        {overall_avg_ts_per_10_tokens[i]}\\t \\\n",
    "        {avg_ts_per_marker[i]}\\t \\\n",
    "        {overall_avg_ts_per_marker[i]}\")\n",
    "\n",
    "print(\"Pearson correlation coefficients and p-values\")\n",
    "print(f\"{avg_dist_pearson}\\t \\\n",
    "      {avg_dist_per_10_tokens_pearson}\\t \\\n",
    "      {overall_avg_dist_per_10_tokens_pearson}\\t \\\n",
    "      {avg_dist_per_marker_pearson}\\t \\\n",
    "      {overall_avg_dist_per_marker_pearson}\\t \\\n",
    "      {avg_jaro_pearson}\\t \\\n",
    "      {avg_transposes_pearson}\\t \\\n",
    "      {avg_ts_per_10_tokens_pearson}\\t \\\n",
    "      {overall_avg_ts_per_10_tokens_pearson}\\t \\\n",
    "      {avg_ts_per_marker_pearson}\\t \\\n",
    "      {overall_avg_ts_per_marker_pearson}\")\n",
    "print(f\"{avg_dist_p}\\t \\\n",
    "      {avg_dist_per_10_tokens_p}\\t \\\n",
    "      {overall_avg_dist_per_10_tokens_p}\\t \\\n",
    "      {avg_dist_per_marker_p}\\t \\\n",
    "      {overall_avg_dist_per_marker_p}\\t \\\n",
    "      {avg_jaro_p}\\t \\\n",
    "      {avg_transposes_p}\\t \\\n",
    "      {avg_ts_per_10_tokens_p}\\t \\\n",
    "      {overall_avg_ts_per_10_tokens_p}\\t \\\n",
    "      {avg_ts_per_marker_p}\\t \\\n",
    "      {overall_avg_ts_per_marker_p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.2308, 9.3846, 1.5385, 10.3846, 19.6154, 2.1333, 6.9667, 3.6, 2.6667, 7.2333], [0.8309, 0.8925, 0.1194, 0.991, 1.8781, 0.1367, 0.4266, 0.2253, 0.1618, 0.5405], [0.8721, 0.8866, 0.1453, 0.9811, 1.8532, 0.1449, 0.4731, 0.2445, 0.1811, 0.4912], [4.6154, 4.6923, 0.7692, 5.1923, 9.8077, 0.4225, 1.3375, 0.6977, 0.67, 2.9867], [4.6154, 4.6923, 0.7692, 5.1923, 9.8077, 0.6275, 2.049, 1.0588, 0.7843, 2.1275], [0.983, 0.9823, 0.9867, 0.9442, 0.8762, 0.9977, 0.9626, 0.9881, 0.973, 0.9464], [11.4615, 11.6923, 10.3846, 34.7692, 63.7692, 2.4, 31.5333, 10.5333, 28.7, 42.5333], [1.0423, 1.117, 0.8018, 3.3012, 6.0543, 0.1538, 1.8318, 0.6877, 1.5918, 3.0442], [1.0828, 1.1047, 0.9811, 3.2849, 6.0247, 0.163, 2.1412, 0.7153, 1.9488, 2.8882], [5.7308, 5.8462, 5.1923, 17.3846, 31.8846, 0.4754, 5.8596, 2.094, 6.3886, 16.5456], [5.7308, 5.8462, 5.1923, 17.3846, 31.8846, 0.7059, 9.2745, 3.098, 8.4412, 12.5098]]\n",
      "0.7604658627428915\t0.7123505863970165\t0.7027875566472089\t0.6798388141678817\t0.673997650177436\t-0.9510729258319484\t0.9370234902298942\t0.9227790459893348\t0.9314488666450534\t0.8878038543189096\t0.9088485508259693\n",
      "0.01066191746238703\t0.020801713773091465\t0.023406716450373777\t0.030555376642130413\t0.032587437760368064\t2.362900175271387e-05\t6.375112399579293e-05\t0.00014161047512379116\t8.889047914585853e-05\t0.0006042073005078471\t0.0002702207937427216\n"
     ]
    }
   ],
   "source": [
    "human_eval_scores = [.48, .48, .88, 1.60, 8.12, .08, 3.28, .51, 1.67, 3.73]\n",
    "scores = \"\"\"9.2308\t9.3846\t1.5385\t10.3846\t19.6154\t2.1333\t6.9667\t3.6000\t2.6667\t7.2333\n",
    "0.8309\t0.8925\t0.1194\t0.9910\t1.8781\t0.1367\t0.4266\t0.2253\t0.1618\t0.5405\n",
    "0.8721\t0.8866\t0.1453\t0.9811\t1.8532\t0.1449\t0.4731\t0.2445\t0.1811\t0.4912\n",
    "4.6154\t4.6923\t0.7692\t5.1923\t9.8077\t0.4225\t1.3375\t0.6977\t0.6700\t2.9867\n",
    "4.6154\t4.6923\t0.7692\t5.1923\t9.8077\t0.6275\t2.0490\t1.0588\t0.7843\t2.1275\n",
    "0.9830\t0.9823\t0.9867\t0.9442\t0.8762\t0.9977\t0.9626\t0.9881\t0.9730\t0.9464\n",
    "11.4615\t11.6923\t10.3846\t34.7692\t63.7692\t2.4000\t31.5333\t10.5333\t28.7000\t42.5333\n",
    "1.0423\t1.1170\t0.8018\t3.3012\t6.0543\t0.1538\t1.8318\t0.6877\t1.5918\t3.0442\n",
    "1.0828\t1.1047\t0.9811\t3.2849\t6.0247\t0.1630\t2.1412\t0.7153\t1.9488\t2.8882\n",
    "5.7308\t5.8462\t5.1923\t17.3846\t31.8846\t0.4754\t5.8596\t2.0940\t6.3886\t16.5456\n",
    "5.7308\t5.8462\t5.1923\t17.3846\t31.8846\t0.7059\t9.2745\t3.0980\t8.4412\t12.5098\"\"\"\n",
    "scores = [[float(n) for n in line.split(\"\\t\")] for line in scores.split(\"\\n\")]\n",
    "print(scores)\n",
    "\n",
    "correlations = []\n",
    "p_values = []\n",
    "for stat in scores:\n",
    "    res = pearsonr(human_eval_scores, stat)\n",
    "    correlations.append(res.statistic)\n",
    "    p_values.append(res.pvalue)\n",
    "print(\"\\t\".join([str(n) for n in correlations]))\n",
    "print(\"\\t\".join([str(n) for n in p_values]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
